{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67873f7a",
   "metadata": {},
   "source": [
    "**0. Load and Prepare Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e18bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "# set visulization style\n",
    "sns.set_style(style=\"whitegrid\")\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b6b219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: c:\\Users\\The Winner\\DSI\\customer_purchasing_behaviour\n",
      "Successfully loaded 'Customer_Purchasing_Behaviors.csv'.\n",
      "Original DataFrame shape: (238, 7)\n"
     ]
    }
   ],
   "source": [
    "# --- Ensure consistent working directory for data loading ---\n",
    "# This block dynamically sets the current working directory to the Git repository root.\n",
    "# This makes data paths reliable for all collaborators, regardless of where they open the notebook.\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "repo_root = current_dir\n",
    "while not os.path.exists(os.path.join(repo_root, '.git')):\n",
    "    # Move up one directory\n",
    "    parent_dir = os.path.dirname(repo_root)\n",
    "    if parent_dir == repo_root: # Reached filesystem root, .git not found\n",
    "        raise FileNotFoundError(\n",
    "            \"Could not find the .git directory. \"\n",
    "            \"Please ensure you are running this code from within a Git repository.\"\n",
    "        )\n",
    "    repo_root = parent_dir\n",
    "\n",
    "if os.getcwd() != repo_root:\n",
    "    os.chdir(repo_root)\n",
    "    print(f\"Working directory set to: {os.getcwd()}\") # Informative print for users\n",
    "\n",
    "\n",
    "# --- Data Loading ---\n",
    "# Path to the data file, relative to the repository root.\n",
    "data_file_name = 'Customer_Purchasing_Behaviors.csv'\n",
    "data_file_path = os.path.join('data', 'raw', data_file_name)\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_file_path)\n",
    "    print(f\"Successfully loaded '{data_file_name}'.\")\n",
    "    #print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{data_file_name}' was not found at '{data_file_path}'.\")\n",
    "    print(\"Please ensure it exists in the 'data/raw/' folder relative to the repository root.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during data loading: {e}\")\n",
    "\n",
    "# Create a copy for feature engineering to keep the original data safe\n",
    "df_eng = df.copy()\n",
    "print(\"Original DataFrame shape:\", df_eng.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5377c20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'age', 'annual_income', 'purchase_amount', 'loyalty_score',\n",
       "       'region', 'purchase_frequency'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng.columns # see the original columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8956554f",
   "metadata": {},
   "source": [
    "**1. Handling Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0852f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DataFrame after handling 'region' ---\n",
      "   user_id region region_grouped  region_South  region_West\n",
      "0        1  North          North         False        False\n",
      "1        2  South          South          True        False\n",
      "2        3   West           West         False         True\n",
      "3        4   East          North         False        False\n",
      "4        5  North          North         False        False\n"
     ]
    }
   ],
   "source": [
    "# Rationale: Group the underrepresented 'East' region to ensure model stability and prevent learning from statistical noise.\n",
    "df_eng['region_grouped'] = df_eng['region'].replace({'East': 'North'})\n",
    "\n",
    "# Convert categorical data into numerical format using One-Hot Encoding\n",
    "region_dummies = pd.get_dummies(df_eng['region_grouped'], prefix='region', drop_first=False) # REMEMBER: When doing One-Hot encoding, do not use North, South and West; only use two(2) of them\n",
    "df_eng = pd.concat([df_eng, region_dummies], axis=1)\n",
    "\n",
    "#print(region_dummies)\n",
    "\n",
    "print(\"\\n--- DataFrame after handling 'region' ---\")\n",
    "print(df_eng[['user_id', 'region', 'region_grouped', 'region_South', 'region_West']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ee7aa",
   "metadata": {},
   "source": [
    "**2. Creating Ratio-Based Features (Behavioral Insights)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56d888e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Newly created ratio features ---\n",
      "   user_id  spend_per_purchase  spend_to_income_ratio\n",
      "0        1           16.666667               0.004444\n",
      "1        2           19.444444               0.006364\n",
      "2        3           22.727273               0.007692\n",
      "3        4           15.000000               0.005000\n",
      "4        5           16.923077               0.004681\n"
     ]
    }
   ],
   "source": [
    "# Rationale: Ratios normalize for effects like purchase frequency and provide deeper behavioral context.\n",
    "df_eng['spend_per_purchase'] = df_eng['purchase_amount'] / df_eng['purchase_frequency']\n",
    "df_eng['spend_to_income_ratio'] = df_eng['purchase_amount'] / df_eng['annual_income']\n",
    "\n",
    "print(\"\\n--- Newly created ratio features ---\")\n",
    "print(df_eng[['user_id', 'spend_per_purchase', 'spend_to_income_ratio']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd49f56",
   "metadata": {},
   "source": [
    "**3. Creating Demographic Tiers (Binning)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "599117f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Newly created demographic tiers ---\n",
      "   user_id  age    age_group  annual_income income_bracket\n",
      "0        1   25  Young_Adult          45000  Medium_Income\n",
      "1        2   34        Adult          55000  Medium_Income\n",
      "2        3   45  Middle_Aged          65000  Medium_Income\n",
      "3        4   22  Young_Adult          30000     Low_Income\n",
      "4        5   29  Young_Adult          47000  Medium_Income\n"
     ]
    }
   ],
   "source": [
    "# Rationale: Converts continuous variables into interpretable categories for business analysis and segmentation.\n",
    "age_bins = [14, 30, 45, 60, 100]\n",
    "age_labels = ['Young_Adult', 'Adult', 'Middle_Aged', 'Senior']\n",
    "df_eng['age_group'] = pd.cut(df_eng['age'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "income_bins = [0, 45000, 90000, 150000]\n",
    "income_labels = ['Low_Income', 'Medium_Income', 'High_Income']\n",
    "df_eng['income_bracket'] = pd.cut(df_eng['annual_income'], bins=income_bins, labels=income_labels, right=False)\n",
    "\n",
    "print(\"\\n--- Newly created demographic tiers ---\")\n",
    "print(df_eng[['user_id', 'age', 'age_group', 'annual_income', 'income_bracket']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287e724",
   "metadata": {},
   "source": [
    "**4. Creating Composite Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07c16a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Newly created composite scores ---\n",
      "   user_id  customer_value_score  churn_risk_score\n",
      "0        1              0.136490          0.829060\n",
      "1        2              0.469039          0.470085\n",
      "2        3              0.716117          0.282051\n",
      "3        4              0.000000          1.000000\n",
      "4        5              0.182326          0.778205\n"
     ]
    }
   ],
   "source": [
    "# Rationale: Combines multiple collinear features into single, powerful, and interpretable scores for value and risk.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(df_eng[['purchase_amount', 'purchase_frequency', 'loyalty_score']])\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=['purchase_scaled', 'frequency_scaled', 'loyalty_scaled'])\n",
    "\n",
    "# Customer Value Score (weighted sum of key metrics)\n",
    "weights = {'monetary': 0.5, 'frequency': 0.25, 'loyalty': 0.25}\n",
    "df_eng['customer_value_score'] = (weights['monetary'] * df_scaled['purchase_scaled'] +\n",
    "                                  weights['frequency'] * df_scaled['frequency_scaled'] +\n",
    "                                  weights['loyalty'] * df_scaled['loyalty_scaled'])\n",
    "\n",
    "# Churn Risk Score (high for low loyalty and frequency)\n",
    "df_eng['churn_risk_score'] = (0.5 * (1 - df_scaled['loyalty_scaled']) +\n",
    "                              0.5 * (1 - df_scaled['frequency_scaled']))\n",
    "\n",
    "print(\"\\n--- Newly created composite scores ---\")\n",
    "print(df_eng[['user_id', 'customer_value_score', 'churn_risk_score']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f967f164",
   "metadata": {},
   "source": [
    "**5. Creating Interaction and Segmentation Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85dffb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Binary Segmentation Flags ---\n",
      "   user_id  is_high_value  is_loyal  is_frequent  is_champion\n",
      "0        1          False     False        False        False\n",
      "1        2          False     False        False        False\n",
      "2        3          False     False        False        False\n",
      "3        4          False     False        False        False\n",
      "4        5          False     False        False        False\n",
      "Number of Champion Customers: 59\n"
     ]
    }
   ],
   "source": [
    "# Rationale: Create binary flags for easy filtering and to identify high-value customer segments like 'Champions'.\n",
    "\n",
    "# Binary Segmentation Flags (based on top 25% percentile)\n",
    "high_value_threshold = df_eng['purchase_amount'].quantile(0.75)\n",
    "high_loyalty_threshold = df_eng['loyalty_score'].quantile(0.75)\n",
    "high_frequency_threshold = df_eng['purchase_frequency'].quantile(0.75)\n",
    "\n",
    "df_eng['is_high_value'] = (df_eng['purchase_amount'] > high_value_threshold)#.astype(int)\n",
    "df_eng['is_loyal'] = (df_eng['loyalty_score'] > high_loyalty_threshold)#.astype(int)\n",
    "df_eng['is_frequent'] = (df_eng['purchase_frequency'] > high_frequency_threshold)#.astype(int)\n",
    "df_eng['is_champion'] = (df_eng['is_high_value'] * df_eng['is_loyal'] * df_eng['is_frequent'])#.astype(int)\n",
    "\n",
    "print(\"\\n--- Binary Segmentation Flags ---\")\n",
    "print(df_eng[['user_id', 'is_high_value', 'is_loyal', 'is_frequent', 'is_champion']].head())\n",
    "print(f\"Number of Champion Customers: {df_eng['is_champion'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f23cc3",
   "metadata": {},
   "source": [
    "**6. Creating Statistical and Business-Savvy Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "664bc616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Growth Potential & Percentile Scores ---\n",
      "    user_id  annual_income  purchase_amount  growth_potential_score\n",
      "4         5          47000              220                     100\n",
      "30       31          55000              350                     100\n",
      "1         2          55000              350                     100\n",
      "45       46          47000              220                     100\n",
      "22       23          63000              460                      88\n"
     ]
    }
   ],
   "source": [
    "# Rationale: Create normalized ranks and business-oriented scores like 'Growth Potential'.\n",
    "df_eng = df_eng.reset_index(drop=True) # this ensures the index is a simple range and matches the Series returned by .rank().\n",
    "# Percentile Ranks\n",
    "df_eng['income_percentile'] = df_eng['annual_income'].rank(pct=True)\n",
    "df_eng['spending_percentile'] = df_eng['purchase_amount'].rank(pct=True)\n",
    "\n",
    "# Growth Potential Score (High Income, Relatively Low Spending)\n",
    "df_eng['growth_potential_score'] = df_eng['income_percentile'] - df_eng['spending_percentile']\n",
    "\n",
    "# Scaling to range [0-100] # NOTE TO BE DELETED: Added after the meeting\n",
    "scaler = MinMaxScaler(feature_range=(0, 100))\n",
    "# Apply scaling\n",
    "df_eng['growth_potential_score'] = scaler.fit_transform(df_eng[['growth_potential_score']]).astype(int)\n",
    "\n",
    "print(\"\\n--- Growth Potential & Percentile Scores ---\")\n",
    "print(df_eng.sort_values('growth_potential_score', ascending=False)[['user_id', 'annual_income', 'purchase_amount', 'growth_potential_score']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cea402f",
   "metadata": {},
   "source": [
    "**7. Core Behaviours - (spend_per_purchase, income_to_spend_ratio, loyalty_per_purchase, age_adjusted_frequency, etc..)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0503de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\The Winner\\AppData\\Local\\Temp\\ipykernel_72\\940941698.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_eng['age_adjusted_percentile'] = df_eng.groupby('age_group')['purchase_frequency'].transform(calc_percentile)\n"
     ]
    }
   ],
   "source": [
    "# First, ensure the age_group column is already created as you described\n",
    "age_bins = [14, 30, 45, 60, 100]\n",
    "age_labels = ['Young_Adult', 'Adult', 'Middle_Aged', 'Senior']\n",
    "df_eng['age_group'] = pd.cut(df_eng['age'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "# Now calculate the percentile of purchase_frequency within each age group\n",
    "def calc_percentile(group):\n",
    "    return group.rank(pct=True)\n",
    "\n",
    "df_eng['age_adjusted_percentile'] = df_eng.groupby('age_group')['purchase_frequency'].transform(calc_percentile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0434d4",
   "metadata": {},
   "source": [
    "**8. Segmentation features - (is_high_value, is_loyal, is_frequent, customer_tier)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb44f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_tier. Would this be market segmentations? Would it come out from clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f24f1f",
   "metadata": {},
   "source": [
    "**9. Demographic behavioural interaction - (young_high_spender, senior_loyal, income_age_segment, etc..)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5919d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic behavioural interaction. Would this be market segmentations? Would it come out from clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ee1bdf",
   "metadata": {},
   "source": [
    "**10. Statistical Features - (frequency_percentile, is_outlier_spender, loyalty_deviation, etc..)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "635af557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define labels for each quantile\n",
    "labels = ['0-25%', '25-50%', '50-75%', '75-100%']\n",
    "# frequency_percentile\n",
    "df_eng['frequency_percentile'] = pd.qcut(df_eng['purchase_frequency'], q=4, labels=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4237c18",
   "metadata": {},
   "source": [
    "**11. Log Transformations - annual_income, purchase_frequency and purchase_amount**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc218b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For features guaranteed to be positive:\n",
    "df_eng['log_purchase_amount'] = np.log(df_eng['purchase_amount'])\n",
    "df_eng['log_annual_income'] = np.log(df_eng['annual_income'])\n",
    "df_eng['log_purchase_frequency'] = np.log(df_eng['purchase_frequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25cd7e2",
   "metadata": {},
   "source": [
    "**12. Finalizing the Model-Ready DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2b21b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FINAL MODEL-READY DATAFRAME ---\n",
      "Shape: (238, 29)\n",
      "Columns: ['user_id', 'age', 'annual_income', 'purchase_amount', 'loyalty_score', 'region', 'region_grouped', 'purchase_frequency', 'customer_value_score', 'churn_risk_score', 'growth_potential_score', 'spend_per_purchase', 'spend_to_income_ratio', 'is_high_value', 'is_loyal', 'is_frequent', 'is_champion', 'age_group', 'age_adjusted_percentile', 'income_bracket', 'income_percentile', 'spending_percentile', 'frequency_percentile', 'log_purchase_amount', 'log_annual_income', 'log_purchase_frequency', 'region_North', 'region_South', 'region_West']\n",
      "   user_id  age  annual_income  purchase_amount  loyalty_score region  \\\n",
      "0        1   25          45000              200            4.5  North   \n",
      "1        2   34          55000              350            7.0  South   \n",
      "2        3   45          65000              500            8.0   West   \n",
      "3        4   22          30000              150            3.0   East   \n",
      "4        5   29          47000              220            4.8  North   \n",
      "\n",
      "  region_grouped  purchase_frequency  customer_value_score  churn_risk_score  \\\n",
      "0          North                  12              0.136490          0.829060   \n",
      "1          South                  18              0.469039          0.470085   \n",
      "2           West                  22              0.716117          0.282051   \n",
      "3          North                  10              0.000000          1.000000   \n",
      "4          North                  13              0.182326          0.778205   \n",
      "\n",
      "   ...  income_bracket  income_percentile  spending_percentile  \\\n",
      "0  ...   Medium_Income           0.140756             0.073529   \n",
      "1  ...   Medium_Income           0.418067             0.292017   \n",
      "2  ...   Medium_Income           0.699580             0.670168   \n",
      "3  ...      Low_Income           0.004202             0.004202   \n",
      "4  ...   Medium_Income           0.207983             0.081933   \n",
      "\n",
      "   frequency_percentile  log_purchase_amount  log_annual_income  \\\n",
      "0                 0-25%             5.298317          10.714418   \n",
      "1                25-50%             5.857933          10.915088   \n",
      "2                50-75%             6.214608          11.082143   \n",
      "3                 0-25%             5.010635          10.308953   \n",
      "4                 0-25%             5.393628          10.757903   \n",
      "\n",
      "   log_purchase_frequency region_North  region_South region_West  \n",
      "0                2.484907         True         False       False  \n",
      "1                2.890372        False          True       False  \n",
      "2                3.091042        False         False        True  \n",
      "3                2.302585         True         False       False  \n",
      "4                2.564949         True         False       False  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Rationale: Create a final, clean DataFrame containing only the identifier and the best engineered features for modeling.\n",
    "# This prevents data leakage and removes redundant columns.\n",
    "\n",
    "features_for_modeling = [\n",
    "    'user_id',\n",
    "    'age',\n",
    "    'annual_income',\n",
    "    'purchase_amount',\n",
    "    'loyalty_score',\n",
    "    'region',\n",
    "    'region_grouped',\n",
    "    'purchase_frequency',\n",
    "    # --- Core Scores ---\n",
    "    'customer_value_score',\n",
    "    'churn_risk_score',\n",
    "    'growth_potential_score',\n",
    "    # --- Behavioral Ratios ---\n",
    "    'spend_per_purchase',\n",
    "    'spend_to_income_ratio',\n",
    "    # --- Key Segments/Flags ---\n",
    "    'is_high_value',\n",
    "    'is_loyal',\n",
    "    'is_frequent',\n",
    "    'is_champion',\n",
    "    # --- Demographics and income bracket---\n",
    "    'age_group',\n",
    "    'age_adjusted_percentile',\n",
    "    'income_bracket',\n",
    "    # --- Added these missing columns ---\n",
    "    'income_percentile',\n",
    "    'spending_percentile',\n",
    "    'frequency_percentile',\n",
    "    # --- Log Transformations ---\n",
    "    'log_purchase_amount',\n",
    "    'log_annual_income',\n",
    "    'log_purchase_frequency'\n",
    "]\n",
    "\n",
    "# Dynamically add the one-hot encoded region columns to the list\n",
    "final_feature_list = features_for_modeling + list(region_dummies.columns)\n",
    "\n",
    "df_model_ready = df_eng[final_feature_list].copy()\n",
    "\n",
    "print(\"\\n--- FINAL MODEL-READY DATAFRAME ---\")\n",
    "print(\"Shape:\", df_model_ready.shape)\n",
    "print(\"Columns:\", df_model_ready.columns.tolist())\n",
    "print(df_model_ready.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e33442",
   "metadata": {},
   "source": [
    "**13. Model Ready Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1e3183c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>loyalty_score</th>\n",
       "      <th>region</th>\n",
       "      <th>purchase_frequency</th>\n",
       "      <th>region_grouped</th>\n",
       "      <th>region_North</th>\n",
       "      <th>region_South</th>\n",
       "      <th>...</th>\n",
       "      <th>is_frequent</th>\n",
       "      <th>is_champion</th>\n",
       "      <th>income_percentile</th>\n",
       "      <th>spending_percentile</th>\n",
       "      <th>growth_potential_score</th>\n",
       "      <th>age_adjusted_percentile</th>\n",
       "      <th>frequency_percentile</th>\n",
       "      <th>log_purchase_amount</th>\n",
       "      <th>log_annual_income</th>\n",
       "      <th>log_purchase_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>45000</td>\n",
       "      <td>200</td>\n",
       "      <td>4.5</td>\n",
       "      <td>North</td>\n",
       "      <td>12</td>\n",
       "      <td>North</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.140756</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>74</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0-25%</td>\n",
       "      <td>5.298317</td>\n",
       "      <td>10.714418</td>\n",
       "      <td>2.484907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>55000</td>\n",
       "      <td>350</td>\n",
       "      <td>7.0</td>\n",
       "      <td>South</td>\n",
       "      <td>18</td>\n",
       "      <td>South</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.418067</td>\n",
       "      <td>0.292017</td>\n",
       "      <td>100</td>\n",
       "      <td>0.261261</td>\n",
       "      <td>25-50%</td>\n",
       "      <td>5.857933</td>\n",
       "      <td>10.915088</td>\n",
       "      <td>2.890372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>65000</td>\n",
       "      <td>500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>West</td>\n",
       "      <td>22</td>\n",
       "      <td>West</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.699580</td>\n",
       "      <td>0.670168</td>\n",
       "      <td>57</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>50-75%</td>\n",
       "      <td>6.214608</td>\n",
       "      <td>11.082143</td>\n",
       "      <td>3.091042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>30000</td>\n",
       "      <td>150</td>\n",
       "      <td>3.0</td>\n",
       "      <td>East</td>\n",
       "      <td>10</td>\n",
       "      <td>North</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>44</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0-25%</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>10.308953</td>\n",
       "      <td>2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>47000</td>\n",
       "      <td>220</td>\n",
       "      <td>4.8</td>\n",
       "      <td>North</td>\n",
       "      <td>13</td>\n",
       "      <td>North</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.207983</td>\n",
       "      <td>0.081933</td>\n",
       "      <td>100</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0-25%</td>\n",
       "      <td>5.393628</td>\n",
       "      <td>10.757903</td>\n",
       "      <td>2.564949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>234</td>\n",
       "      <td>40</td>\n",
       "      <td>60000</td>\n",
       "      <td>450</td>\n",
       "      <td>7.2</td>\n",
       "      <td>West</td>\n",
       "      <td>20</td>\n",
       "      <td>West</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>44</td>\n",
       "      <td>0.558559</td>\n",
       "      <td>25-50%</td>\n",
       "      <td>6.109248</td>\n",
       "      <td>11.002100</td>\n",
       "      <td>2.995732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>235</td>\n",
       "      <td>38</td>\n",
       "      <td>59000</td>\n",
       "      <td>430</td>\n",
       "      <td>6.9</td>\n",
       "      <td>North</td>\n",
       "      <td>20</td>\n",
       "      <td>North</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.510504</td>\n",
       "      <td>0.476891</td>\n",
       "      <td>59</td>\n",
       "      <td>0.558559</td>\n",
       "      <td>25-50%</td>\n",
       "      <td>6.063785</td>\n",
       "      <td>10.985293</td>\n",
       "      <td>2.995732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>236</td>\n",
       "      <td>54</td>\n",
       "      <td>74000</td>\n",
       "      <td>630</td>\n",
       "      <td>9.4</td>\n",
       "      <td>South</td>\n",
       "      <td>27</td>\n",
       "      <td>South</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.957983</td>\n",
       "      <td>0.957983</td>\n",
       "      <td>44</td>\n",
       "      <td>0.861842</td>\n",
       "      <td>75-100%</td>\n",
       "      <td>6.445720</td>\n",
       "      <td>11.211820</td>\n",
       "      <td>3.295837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>237</td>\n",
       "      <td>32</td>\n",
       "      <td>52000</td>\n",
       "      <td>360</td>\n",
       "      <td>5.8</td>\n",
       "      <td>West</td>\n",
       "      <td>18</td>\n",
       "      <td>West</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.304622</td>\n",
       "      <td>0.313025</td>\n",
       "      <td>40</td>\n",
       "      <td>0.261261</td>\n",
       "      <td>25-50%</td>\n",
       "      <td>5.886104</td>\n",
       "      <td>10.858999</td>\n",
       "      <td>2.890372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>238</td>\n",
       "      <td>31</td>\n",
       "      <td>51000</td>\n",
       "      <td>340</td>\n",
       "      <td>5.6</td>\n",
       "      <td>North</td>\n",
       "      <td>17</td>\n",
       "      <td>North</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.273109</td>\n",
       "      <td>0.273109</td>\n",
       "      <td>44</td>\n",
       "      <td>0.117117</td>\n",
       "      <td>0-25%</td>\n",
       "      <td>5.828946</td>\n",
       "      <td>10.839581</td>\n",
       "      <td>2.833213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  age  annual_income  purchase_amount  loyalty_score region  \\\n",
       "0          1   25          45000              200            4.5  North   \n",
       "1          2   34          55000              350            7.0  South   \n",
       "2          3   45          65000              500            8.0   West   \n",
       "3          4   22          30000              150            3.0   East   \n",
       "4          5   29          47000              220            4.8  North   \n",
       "..       ...  ...            ...              ...            ...    ...   \n",
       "233      234   40          60000              450            7.2   West   \n",
       "234      235   38          59000              430            6.9  North   \n",
       "235      236   54          74000              630            9.4  South   \n",
       "236      237   32          52000              360            5.8   West   \n",
       "237      238   31          51000              340            5.6  North   \n",
       "\n",
       "     purchase_frequency region_grouped  region_North  region_South  ...  \\\n",
       "0                    12          North          True         False  ...   \n",
       "1                    18          South         False          True  ...   \n",
       "2                    22           West         False         False  ...   \n",
       "3                    10          North          True         False  ...   \n",
       "4                    13          North          True         False  ...   \n",
       "..                  ...            ...           ...           ...  ...   \n",
       "233                  20           West         False         False  ...   \n",
       "234                  20          North          True         False  ...   \n",
       "235                  27          South         False          True  ...   \n",
       "236                  18           West         False         False  ...   \n",
       "237                  17          North          True         False  ...   \n",
       "\n",
       "     is_frequent  is_champion  income_percentile spending_percentile  \\\n",
       "0          False        False           0.140756            0.073529   \n",
       "1          False        False           0.418067            0.292017   \n",
       "2          False        False           0.699580            0.670168   \n",
       "3          False        False           0.004202            0.004202   \n",
       "4          False        False           0.207983            0.081933   \n",
       "..           ...          ...                ...                 ...   \n",
       "233        False        False           0.544118            0.544118   \n",
       "234        False        False           0.510504            0.476891   \n",
       "235         True         True           0.957983            0.957983   \n",
       "236        False        False           0.304622            0.313025   \n",
       "237        False        False           0.273109            0.273109   \n",
       "\n",
       "    growth_potential_score  age_adjusted_percentile  frequency_percentile  \\\n",
       "0                       74                 0.333333                 0-25%   \n",
       "1                      100                 0.261261                25-50%   \n",
       "2                       57                 0.111842                50-75%   \n",
       "3                       44                 0.019608                 0-25%   \n",
       "4                      100                 0.382353                 0-25%   \n",
       "..                     ...                      ...                   ...   \n",
       "233                     44                 0.558559                25-50%   \n",
       "234                     59                 0.558559                25-50%   \n",
       "235                     44                 0.861842               75-100%   \n",
       "236                     40                 0.261261                25-50%   \n",
       "237                     44                 0.117117                 0-25%   \n",
       "\n",
       "     log_purchase_amount  log_annual_income  log_purchase_frequency  \n",
       "0               5.298317          10.714418                2.484907  \n",
       "1               5.857933          10.915088                2.890372  \n",
       "2               6.214608          11.082143                3.091042  \n",
       "3               5.010635          10.308953                2.302585  \n",
       "4               5.393628          10.757903                2.564949  \n",
       "..                   ...                ...                     ...  \n",
       "233             6.109248          11.002100                2.995732  \n",
       "234             6.063785          10.985293                2.995732  \n",
       "235             6.445720          11.211820                3.295837  \n",
       "236             5.886104          10.858999                2.890372  \n",
       "237             5.828946          10.839581                2.833213  \n",
       "\n",
       "[238 rows x 29 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exporting the feature engineered data to a csv file\n",
    "model_ready_data = pd.DataFrame(df_model_ready, columns=df_eng.columns)\n",
    "model_ready_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb97060",
   "metadata": {},
   "source": [
    "**14. Write Data to CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be5d13ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ready_data.to_csv(os.path.join( 'data','processed', 'df_eng_customer_purchasing_features.csv'), float_format='%.4f', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
