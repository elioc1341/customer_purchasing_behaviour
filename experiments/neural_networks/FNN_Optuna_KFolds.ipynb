{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b691b112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 02:11:02,900, 2692577433.py, 34, INFO, load_dotenv() returned: True\n",
      "2025-08-03 02:11:02,900, 2692577433.py, 57, INFO, Working directory set to: c:\\Users\\The Winner\\DSI\\customer_purchasing_behaviour\n",
      "2025-08-03 02:11:02,900, 2692577433.py, 67, INFO, Successfully loaded 'df_eng_customer_purchasing_features.csv' into the DataFrame named df.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\The Winner\\AppData\\Local\\Temp\\ipykernel_4700\\2692577433.py\", line 77, in <module>\n",
      "    _logs.info(\"Current directory:\", os.getcwd())\n",
      "Message: 'Current directory:'\n",
      "Arguments: ('c:\\\\Users\\\\The Winner\\\\DSI\\\\customer_purchasing_behaviour',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\The Winner\\AppData\\Local\\Temp\\ipykernel_4700\\2692577433.py\", line 77, in <module>\n",
      "    _logs.info(\"Current directory:\", os.getcwd())\n",
      "Message: 'Current directory:'\n",
      "Arguments: ('c:\\\\Users\\\\The Winner\\\\DSI\\\\customer_purchasing_behaviour',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\The Winner\\AppData\\Local\\Temp\\ipykernel_4700\\2692577433.py\", line 81, in <module>\n",
      "    _logs.info(\"New directory:\", os.getcwd())\n",
      "Message: 'New directory:'\n",
      "Arguments: ('c:\\\\Users\\\\The Winner\\\\DSI\\\\customer_purchasing_behaviour\\\\experiments\\\\neural_networks',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\The Winner\\AppData\\Local\\Temp\\ipykernel_4700\\2692577433.py\", line 81, in <module>\n",
      "    _logs.info(\"New directory:\", os.getcwd())\n",
      "Message: 'New directory:'\n",
      "Arguments: ('c:\\\\Users\\\\The Winner\\\\DSI\\\\customer_purchasing_behaviour\\\\experiments\\\\neural_networks',)\n",
      "2025-08-03 02:11:02,931, 2692577433.py, 125, INFO, Dataset sizes:\n",
      "2025-08-03 02:11:02,932, 2692577433.py, 126, INFO,   Train (for KFold CV): 190\n",
      "2025-08-03 02:11:02,939, 2692577433.py, 127, INFO,   Holdout (not used): 48\n",
      "2025-08-03 02:11:02,943, 2692577433.py, 763, INFO, Starting hyperparameter optimization...\n",
      "[I 2025-08-03 02:11:05,037] A new study created in memory with name: neural_net_optimization\n",
      "2025-08-03 02:11:05,037, 2692577433.py, 441, INFO, Starting Optuna optimization with 50 trials...\n",
      "[W 2025-08-03 02:11:05,037] Trial 0 failed with parameters: {} because of the following error: TypeError('Trial.suggest_categorical() takes 3 positional arguments but 4 were given').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\The Winner\\AppData\\Local\\Temp\\ipykernel_4700\\2692577433.py\", line 446, in <lambda>\n",
      "    lambda trial: objective(trial, X_train, y_train, data_file_name),\n",
      "  File \"C:\\Users\\The Winner\\AppData\\Local\\Temp\\ipykernel_4700\\2692577433.py\", line 227, in objective\n",
      "    width_1st_layer = trial.suggest_categorical('width_1st_layer', 2, 32)\n",
      "TypeError: Trial.suggest_categorical() takes 3 positional arguments but 4 were given\n",
      "[W 2025-08-03 02:11:05,037] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Trial.suggest_categorical() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 764\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;66;03m##################################################################################################################################################\u001b[39;00m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;66;03m# Step 1: Find best hyperparameters\u001b[39;00m\n\u001b[0;32m    763\u001b[0m _logs\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting hyperparameter optimization...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 764\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43mrun_optuna_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    766\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mneural_net_optimization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    770\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;66;03m# Step 2: Train final model with best parameters\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining final model with optimized parameters...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 445\u001b[0m, in \u001b[0;36mrun_optuna_optimization\u001b[1;34m(X_train, y_train, data_file_name, n_trials, study_name)\u001b[0m\n\u001b[0;32m    442\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# Optimize\u001b[39;00m\n\u001b[1;32m--> 445\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_file_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_logs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrial \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumber\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m finished with value: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.4f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    452\u001b[0m optimization_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\optuna\\study\\study.py:489\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    389\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    398\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 64\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    249\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    252\u001b[0m ):\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\miniconda3\\envs\\gtx1060_tf\\lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[1], line 446\u001b[0m, in \u001b[0;36mrun_optuna_optimization.<locals>.<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m    442\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# Optimize\u001b[39;00m\n\u001b[0;32m    445\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[1;32m--> 446\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_file_name\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    447\u001b[0m     n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    448\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mlambda\u001b[39;00m study, trial: _logs\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m finished with value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m    449\u001b[0m )\n\u001b[0;32m    451\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    452\u001b[0m optimization_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[1;32mIn[1], line 227\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial, X_train, y_train, data_file_name)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Optuna objective function for hyperparameter optimization\"\"\"\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# Suggest hyperparameters\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m width_1st_layer \u001b[38;5;241m=\u001b[39m \u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwidth_1st_layer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m width_2nd_layer \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth_2nd_layer\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m1\u001b[39m])\u001b[38;5;66;03m#[8, 16, 32, 64])\u001b[39;00m\n\u001b[0;32m    229\u001b[0m width_3rd_layer \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth_3rd_layer\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m1\u001b[39m])\u001b[38;5;66;03m#[4, 8, 16, 32])\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Trial.suggest_categorical() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "##################################################################################################################################################\n",
    "# Importing libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "import sys\n",
    "import pprint\n",
    "import optuna\n",
    "##################################################################################################################################################\n",
    "# Logger\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "sys.path.append(\"./loggers/\")\n",
    "from utils.logger import get_logger\n",
    "_logs = get_logger(__name__)\n",
    "os.chdir('./experiments/neural_networks') if not load_dotenv() else None\n",
    "load_dotenv()\n",
    "_logs.info(f\"load_dotenv() returned: {load_dotenv()}\")\n",
    "##################################################################################################################################################\n",
    "# Load csv into df\n",
    "\n",
    "# --- Ensure consistent working directory for data loading ---\n",
    "# This block dynamically sets the current working directory to the Git repository root.\n",
    "# This makes data paths reliable for all collaborators, regardless of where they open the notebook.\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "repo_root = current_dir\n",
    "while not os.path.exists(os.path.join(repo_root, '.git')):\n",
    "    # Move up one directory\n",
    "    parent_dir = os.path.dirname(repo_root)\n",
    "    if parent_dir == repo_root: # Reached filesystem root, .git not found\n",
    "        raise FileNotFoundError(\n",
    "            \"Could not find the .git directory. \"\n",
    "            \"Please ensure you are running this code from within a Git repository.\"\n",
    "        )\n",
    "    repo_root = parent_dir\n",
    "\n",
    "# Change the current working directory if it's not already the repo root\n",
    "if os.getcwd() != repo_root:\n",
    "    os.chdir(repo_root)\n",
    "    _logs.info(f\"Working directory set to: {os.getcwd()}\") # Informative print for users\n",
    "\n",
    "\n",
    "# --- Data Loading ---\n",
    "# Path to the data file, relative to the repository root.\n",
    "data_file_name = 'df_eng_customer_purchasing_features.csv'\n",
    "data_file_path = os.path.join('data', 'processed', data_file_name)\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_file_path)\n",
    "    _logs.info(f\"Successfully loaded '{data_file_name}' into the DataFrame named df.\")\n",
    "    #_logs.info(df.head())\n",
    "except FileNotFoundError:\n",
    "    _logs.info(f\"Error: The file '{data_file_name}' was not found at '{data_file_path}'.\")\n",
    "    _logs.info(\"Please ensure it exists in the 'data/processed/' folder relative to the repository root.\")\n",
    "except Exception as e:\n",
    "    _logs.info(f\"An error occurred during data loading: {e}\")\n",
    "##################################################################################################################################################\n",
    "#Change the working directory\n",
    "# Check current directory\n",
    "_logs.info(\"Current directory:\", os.getcwd())\n",
    "# Change to new directory\n",
    "os.chdir(\"./experiments/neural_networks\")\n",
    "# Verify the change\n",
    "_logs.info(\"New directory:\", os.getcwd())\n",
    "##################################################################################################################################################\n",
    "# Split the data between train portion and a holdout portion that will be used in another Notebook for validation and test\n",
    "# Hold out 20% of the dataset (to become val + test in another Notebook, we will not use it here)\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(df.drop(['purchase_amount', 'log_purchase_amount'], axis=1), df[['purchase_amount', 'log_purchase_amount']], test_size=0.2, random_state=42)\n",
    "df = pd.concat([X_train, y_train], axis=1)\n",
    "##################################################################################################################################################\n",
    "# Prepare data: scale numerical and encode categorical\n",
    "# Preprocessing: Prepare Inputs\n",
    "\n",
    "# Extract relevant columns\n",
    "numerical_cols = ['age', 'annual_income', 'loyalty_score', 'purchase_frequency', 'log_annual_income', 'log_purchase_frequency']\n",
    "categorical_cols = ['region_grouped']\n",
    "target_col = 'purchase_amount'\n",
    "target_col_log = 'log_purchase_amount'\n",
    "\n",
    "# Filter to only use columns that actually exist\n",
    "existing_numerical_cols = [col for col in numerical_cols if col in df.columns]\n",
    "existing_categorical_cols = [col for col in categorical_cols if col in df.columns]\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_num = scaler.fit_transform(df[existing_numerical_cols])\n",
    "\n",
    "# Encode categorical feature\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_cat = encoder.fit_transform(df[existing_categorical_cols])\n",
    "\n",
    "# Create DataFrames with distinct column names\n",
    "num_df = pd.DataFrame(X_num, columns=existing_numerical_cols)\n",
    "cat_columns = encoder.get_feature_names_out(existing_categorical_cols)\n",
    "cat_df = pd.DataFrame(X_cat, columns=cat_columns)\n",
    "\n",
    "# Combine safely\n",
    "combined_df = pd.concat([num_df, cat_df], axis=1)\n",
    "\n",
    "# Convert to torch tensor\n",
    "X_train = torch.tensor(combined_df.values, dtype=torch.float32)\n",
    "\n",
    "# Target variable\n",
    "y_train = torch.tensor(df[target_col].values, dtype=torch.float32).view(-1, 1)\n",
    "y_train_log = torch.tensor(df[target_col_log].values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Print dataset sizes and set max batch sizes\n",
    "_logs.info(f\"Dataset sizes:\")\n",
    "_logs.info(f\"  Train (for KFold CV): {len(X_train)}\")\n",
    "_logs.info(f\"  Holdout (not used): {len(X_holdout)}\")\n",
    "##################################################################################################################################################\n",
    "# Gradient-Based Adaptive Batch Size Class\n",
    "class GradientAdaptiveBatchingLearning:\n",
    "    def __init__(self, initial_batch_size=16, initial_lr=0.001,\n",
    "                 grad_threshold=0.01, batch_multiplier=1.4, lr_multiplier=0.8, grad_threshold_multiplier=0.25, lr_min=0.0005, max_batch_size=142):\n",
    "        self.current_batch_size = initial_batch_size\n",
    "        self.current_lr = initial_lr\n",
    "        self.grad_threshold = grad_threshold\n",
    "        self.batch_multiplier = batch_multiplier\n",
    "        self.lr_multiplier = lr_multiplier\n",
    "        self.grad_threshold_multiplier = grad_threshold_multiplier\n",
    "        self.lr_min = lr_min\n",
    "        self.max_batch_size = max_batch_size\n",
    "        self.loss_history = []\n",
    "        self.update_count = 0\n",
    "            \n",
    "    def update_params(self, current_loss, epoch):\n",
    "        self.loss_history.append(current_loss)\n",
    "        \n",
    "        # Need at least 5 epochs of history for gradient calculation\n",
    "        if len(self.loss_history) >= 5:\n",
    "            # Calculate gradient (first derivative) over recent losses\n",
    "            recent_losses = self.loss_history[-5:]\n",
    "            gradient = np.mean(np.diff(recent_losses))\n",
    "            \n",
    "            # Additional stability check: don't update too frequently\n",
    "            epochs_since_update = len(self.loss_history) - self.update_count\n",
    "            \n",
    "            # If gradient is small (slow improvement) and enough time passed\n",
    "            if abs(gradient) < self.grad_threshold and epochs_since_update >= 100:\n",
    "                new_batch_size = min(\n",
    "                    int(self.current_batch_size * self.batch_multiplier), \n",
    "                    self.max_batch_size\n",
    "                )\n",
    "                # Decrease learning rate when increasing batch size\n",
    "                lr_scaling = self.lr_multiplier\n",
    "                self.current_lr = max(\n",
    "                    self.current_lr * lr_scaling, \n",
    "                    self.lr_min\n",
    "                )\n",
    "                self.current_batch_size = new_batch_size\n",
    "                self.update_count = len(self.loss_history)\n",
    "                \n",
    "                _logs.info(f\"Epoch {epoch}: Gradient = {gradient:.6f} < {self.grad_threshold}\")\n",
    "                _logs.info(f\"  → Increased batch size: {int(self.current_batch_size/self.batch_multiplier)} → {self.current_batch_size}\")\n",
    "                _logs.info(f\"  → Decreased learning rate: {self.current_lr/lr_scaling:.6f} → {self.current_lr:.6f}\")\n",
    "                \n",
    "                # Gradient Threshold updated\n",
    "                self.grad_threshold = self.grad_threshold * self.grad_threshold_multiplier\n",
    "                \n",
    "        return self.current_batch_size, self.current_lr\n",
    "##################################################################################################################################################\n",
    "# Define the Neural Network Model\n",
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_size, width_1st_layer, width_2nd_layer, width_3rd_layer, \n",
    "                 width_4th_layer, width_output_layer, dropout1, dropout2, dropout3, dropout4):\n",
    "        super(FeedforwardNN, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        prev_layer_size = input_size      \n",
    "        # First hidden layer (always exists)\n",
    "        layers.extend([\n",
    "            nn.Linear(prev_layer_size , width_1st_layer),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout1)\n",
    "        ])\n",
    "        prev_layer_size = width_1st_layer\n",
    "        \n",
    "        # Second hidden layer (conditional)\n",
    "        if width_2nd_layer > 0:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_layer_size, width_2nd_layer),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout2)\n",
    "            ])\n",
    "            prev_layer_size = width_2nd_layer\n",
    "\n",
    "        # Third hidden layer (conditional)\n",
    "        if width_3rd_layer > 0:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_layer_size, width_3rd_layer),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout3)\n",
    "            ])\n",
    "            prev_layer_size = width_3rd_layer\n",
    "        \n",
    "        # Fourth hidden layer (conditional)\n",
    "        if width_4th_layer > 0:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_layer_size, width_4th_layer),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout4)\n",
    "            ])\n",
    "            prev_layer_size = width_4th_layer\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(prev_layer_size, width_output_layer))\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "##################################################################################################################################################\n",
    "def init_weights(m):\n",
    "    '''Make the weight initialization reproducible'''\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias, 0.01)\n",
    "##################################################################################################################################################\n",
    "# Metric computation functions\n",
    "def compute_rmse(predictions, targets):\n",
    "    return torch.sqrt(F.mse_loss(predictions, targets))\n",
    "\n",
    "def compute_mae(predictions, targets):\n",
    "    return torch.mean(torch.abs(predictions - targets))\n",
    "\n",
    "def compute_mape(predictions, targets):\n",
    "    return torch.mean(torch.abs((predictions - targets) / targets) * 100)\n",
    "\n",
    "def compute_r2(predictions, targets):\n",
    "    ss_res = torch.sum((targets - predictions) ** 2)\n",
    "    ss_tot = torch.sum((targets - torch.mean(targets)) ** 2)\n",
    "    return 1 - ss_res / ss_tot\n",
    "##################################################################################################################################################\n",
    "def objective(trial, X_train, y_train, data_file_name=\"default_dataset\"):\n",
    "    \"\"\"Optuna objective function for hyperparameter optimization\"\"\"\n",
    "    \n",
    "    # First decide the architecture depth\n",
    "    n_hidden_layers = trial.suggest_categorical('n_hidden_layers', [1, 2, 3, 4])\n",
    "    \n",
    "    # Always suggest first layer\n",
    "    width_1st_layer = trial.suggest_categorical('width_1st_layer', [8, 16, 32, 64])\n",
    "    dropout1 = trial.suggest_float('dropout1', 0.0, 0.5, step=0.1)  # Always used\n",
    "    \n",
    "    # Conditional suggestions based on depth\n",
    "    if n_hidden_layers >= 2:\n",
    "        width_2nd_layer = trial.suggest_categorical('width_2nd_layer', [4, 8, 16, 32])\n",
    "        dropout2 = trial.suggest_float('dropout2', 0.0, 0.5, step=0.1)\n",
    "    else:\n",
    "        width_2nd_layer = 0\n",
    "        dropout2 = 0.0\n",
    "        \n",
    "    if n_hidden_layers >= 3:\n",
    "        width_3rd_layer = trial.suggest_categorical('width_3rd_layer', [2, 4, 8, 16])\n",
    "        dropout3 = trial.suggest_float('dropout3', 0.0, 0.5, step=0.1)\n",
    "    else:\n",
    "        width_3rd_layer = 0\n",
    "        dropout3 = 0.0\n",
    "        \n",
    "    if n_hidden_layers >= 4:\n",
    "        width_4th_layer = trial.suggest_categorical('width_4th_layer', [2, 4, 8])\n",
    "        dropout4 = trial.suggest_float('dropout4', 0.0, 0.5, step=0.1)\n",
    "    else:\n",
    "        width_4th_layer = 0\n",
    "        dropout4 = 0.0\n",
    "    \n",
    "    width_output_layer = 1  # Keep fixed for regression\n",
    "    \n",
    "    # Adaptive batching parameters\n",
    "    initial_lr = trial.suggest_float('initial_lr', 0.005, 0.01)\n",
    "    initial_batch_size = trial.suggest_categorical('initial_batch_size', [8, 16, 32])\n",
    "    #grad_threshold = trial.suggest_float('grad_threshold', 0.1, 1)\n",
    "    grad_threshold = 1\n",
    "    batch_multiplier = trial.suggest_float('batch_multiplier', 1.5, 2.5)\n",
    "    lr_multiplier = trial.suggest_float('lr_multiplier', 0.4, 0.7)\n",
    "    grad_threshold_multiplier = trial.suggest_categorical('grad_threshold_multiplier', [0.1, 0.25, 0.4, 0.55])\n",
    "    lr_min = trial.suggest_float('lr_min', 0.0001, 0.001)\n",
    "    \n",
    "    # Fixed parameters\n",
    "    n_folds = 3  # Reduced for faster optimization\n",
    "    epoch_max = 10000  # Reduced for faster trials\n",
    "    patience = 5000  # Reduced patience\n",
    "    \n",
    "    params = {\n",
    "        \"dataset\": data_file_name,\n",
    "        \"width_1st_layer\": width_1st_layer,\n",
    "        \"dropout1\": dropout1,\n",
    "        \"dropout2\": dropout2,\n",
    "        \"dropout3\": dropout3,\n",
    "        \"dropout4\": dropout4,\n",
    "        \"width_2nd_layer\": width_2nd_layer,\n",
    "        \"width_3rd_layer\": width_3rd_layer,\n",
    "        \"width_4th_layer\": width_4th_layer,\n",
    "        \"width_output_layer\": width_output_layer,\n",
    "        \"activation\": \"relu\",\n",
    "        \"criterion\": \"Mean Squared Error (MSE) loss\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"adaptive_batching_learning_rate\": True,\n",
    "        \"initial_lr\": initial_lr,\n",
    "        \"initial_batch_size\": initial_batch_size,\n",
    "        \"max_batch_size\": len(X_train),\n",
    "        \"grad_threshold\": grad_threshold,\n",
    "        \"batch_multiplier\": batch_multiplier,\n",
    "        \"lr_multiplier\": lr_multiplier,\n",
    "        \"grad_threshold_multiplier\": grad_threshold_multiplier,\n",
    "        \"lr_min\": lr_min,\n",
    "        \"epoch_max\": epoch_max,\n",
    "        \"trial_number\": trial.number\n",
    "    }\n",
    "    \n",
    "    # KFold setup\n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Store validation scores for each fold\n",
    "    fold_val_scores = []\n",
    "    \n",
    "    # KFold cross-validation loop\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train)):\n",
    "        # Create fold-specific train/validation splits\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        y_train_fold = y_train[train_idx]\n",
    "        X_val_fold = X_train[val_idx]\n",
    "        y_val_fold = y_train[val_idx]\n",
    "\n",
    "        # Make it reproducible\n",
    "        SEED = 42\n",
    "        random.seed(SEED)\n",
    "        np.random.seed(SEED)\n",
    "        torch.manual_seed(SEED)\n",
    "        torch.cuda.manual_seed(SEED)\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "        # Initialize model\n",
    "        model = FeedforwardNN(\n",
    "            input_size=X_train_fold.shape[1],\n",
    "            width_1st_layer=width_1st_layer,\n",
    "            width_2nd_layer=width_2nd_layer,\n",
    "            width_3rd_layer=width_3rd_layer,\n",
    "            width_4th_layer=width_4th_layer,\n",
    "            width_output_layer=width_output_layer,\n",
    "            dropout1=dropout1,\n",
    "            dropout2=dropout2,\n",
    "            dropout3=dropout3,\n",
    "            dropout4=dropout4            \n",
    "        )\n",
    "        model.apply(init_weights)\n",
    "\n",
    "        # Setup device\n",
    "        device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "        \n",
    "        # Move data to device\n",
    "        X_train_fold = X_train_fold.to(device)\n",
    "        y_train_fold = y_train_fold.to(device)\n",
    "        X_val_fold = X_val_fold.to(device)\n",
    "        y_val_fold = y_val_fold.to(device)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Initialize adaptive batch trainer\n",
    "        adaptive_trainer = GradientAdaptiveBatchingLearning(\n",
    "            initial_batch_size=initial_batch_size,\n",
    "            initial_lr=initial_lr,\n",
    "            grad_threshold=grad_threshold,\n",
    "            batch_multiplier=batch_multiplier,\n",
    "            lr_multiplier=lr_multiplier,\n",
    "            grad_threshold_multiplier=grad_threshold_multiplier,\n",
    "            lr_min=lr_min,\n",
    "            max_batch_size=len(X_train_fold)\n",
    "        )\n",
    "        \n",
    "        # Create DataLoaders\n",
    "        train_dataset = TensorDataset(X_train_fold, y_train_fold)\n",
    "        val_dataset = TensorDataset(X_val_fold, y_val_fold)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=initial_batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=initial_batch_size, shuffle=False)\n",
    "        \n",
    "        # Training setup\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=adaptive_trainer.current_lr)\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        trigger_times = 0\n",
    "        min_delta = 0\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(epoch_max):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            epoch_train_loss = 0.0\n",
    "            num_train_batches = 0\n",
    "            \n",
    "            for batch_X, batch_y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                output = model(batch_X)\n",
    "                loss = criterion(output, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_train_loss += loss.item()\n",
    "                num_train_batches += 1\n",
    "            \n",
    "            avg_train_loss = epoch_train_loss / num_train_batches\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            epoch_val_loss = 0.0\n",
    "            num_val_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_X, batch_y in val_loader:\n",
    "                    val_output = model(batch_X)\n",
    "                    val_loss = criterion(val_output, batch_y)\n",
    "                    epoch_val_loss += val_loss.item()\n",
    "                    num_val_batches += 1\n",
    "            \n",
    "            avg_val_loss = epoch_val_loss / num_val_batches\n",
    "            \n",
    "            # Adaptive batch size and learning rate update\n",
    "            new_batch_size, new_lr = adaptive_trainer.update_params(avg_val_loss, epoch)\n",
    "            \n",
    "            # Update optimizer learning rate if changed\n",
    "            if new_lr != optimizer.param_groups[0]['lr']:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = new_lr\n",
    "            \n",
    "            # Create new dataloader if batch size changed\n",
    "            if new_batch_size != train_loader.batch_size:\n",
    "                train_loader = DataLoader(train_dataset, batch_size=new_batch_size, shuffle=True)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=new_batch_size, shuffle=False)\n",
    "            \n",
    "            # Early stopping logic\n",
    "            if avg_val_loss + min_delta < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                trigger_times = 0\n",
    "            else:\n",
    "                trigger_times += 1\n",
    "                if trigger_times >= patience:\n",
    "                    break\n",
    "            \n",
    "            # Report intermediate results to Optuna for pruning\n",
    "            trial.report(avg_val_loss, epoch)\n",
    "            \n",
    "            # Handle pruning\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "        # Final validation score for this fold\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_output = model(X_val_fold)\n",
    "            final_val_loss = criterion(val_output, y_val_fold)\n",
    "            fold_val_scores.append(final_val_loss.item())\n",
    "        \n",
    "        # Clean up\n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Return mean validation score across all folds\n",
    "    mean_val_score = np.mean(fold_val_scores)\n",
    "    return mean_val_score\n",
    "##################################################################################################################################################\n",
    "def run_optuna_optimization(X_train, y_train, data_file_name=\"default_dataset\", \n",
    "                           n_trials=50, study_name=\"neural_net_optimization\"):\n",
    "    \"\"\"Run Optuna hyperparameter optimization\"\"\"\n",
    "    \n",
    "    # Set up MLflow\n",
    "    mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\", \"file:./mlruns\"))\n",
    "    mlflow.set_experiment(os.getenv(\"MLFLOW_EXPERIMENT_NAME\", \"optuna_neural_net_optimization\"))\n",
    "    \n",
    "    # Create Optuna study\n",
    "    study = optuna.create_study(\n",
    "        direction='minimize',\n",
    "        study_name=study_name,\n",
    "        storage=None,  # Use in-memory storage, can be changed to persistent storage\n",
    "        pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=100),\n",
    "        sampler=optuna.samplers.TPESampler(seed=42)\n",
    "    )\n",
    "    \n",
    "    _logs.info(f\"Starting Optuna optimization with {n_trials} trials...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Optimize\n",
    "    study.optimize(\n",
    "        lambda trial: objective(trial, X_train, y_train, data_file_name),\n",
    "        n_trials=n_trials,\n",
    "        callbacks=[lambda study, trial: _logs.info(f\"Trial {trial.number} finished with value: {trial.value:.4f}\")]\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    optimization_time = end_time - start_time\n",
    "    \n",
    "    _logs.info(f\"\\nOptimization completed in {optimization_time:.2f} seconds\")\n",
    "    _logs.info(f\"Best trial: {study.best_trial.number}\")\n",
    "    _logs.info(f\"Best value: {study.best_value:.4f}\")\n",
    "    _logs.info(f\"Best parameters:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        _logs.info(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Log best results to MLflow\n",
    "    with mlflow.start_run(run_name=f\"OPTUNA_BEST_{study_name}\"):\n",
    "        # Log best parameters\n",
    "        mlflow.log_params(study.best_params)\n",
    "        \n",
    "        # Log best score\n",
    "        mlflow.log_metric(\"best_val_loss\", study.best_value)\n",
    "        mlflow.log_metric(\"n_trials\", n_trials)\n",
    "        mlflow.log_metric(\"optimization_time_seconds\", optimization_time)\n",
    "        \n",
    "        # Log study statistics\n",
    "        mlflow.log_metric(\"n_completed_trials\", len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]))\n",
    "        mlflow.log_metric(\"n_pruned_trials\", len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]))\n",
    "    \n",
    "    return study\n",
    "##################################################################################################################################################\n",
    "def train_final_model_with_best_params(X_train, y_train, best_params, data_file_name=\"default_dataset\"):\n",
    "    \"\"\"Train final model with best parameters found by Optuna\"\"\"\n",
    "    \n",
    "    _logs.info(\"\\nTraining final model with best parameters...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Extended training parameters for final model\n",
    "    n_folds = 4\n",
    "    epoch_max = 25000\n",
    "    patience = 10000\n",
    "    \n",
    "    # Update parameters with best found values\n",
    "    params = {\n",
    "        \"dataset\": data_file_name,\n",
    "        \"width_1st_layer\": best_params['width_1st_layer'],\n",
    "        \"dropout1\": best_params['dropout1'],\n",
    "        \"width_2nd_layer\": best_params['width_2nd_layer'],\n",
    "        \"dropout2\": best_params['dropout2'],\n",
    "        \"width_3rd_layer\": best_params['width_3rd_layer'],\n",
    "        \"dropout3\": best_params['dropout3'],\n",
    "        \"width_4th_layer\": best_params['width_4th_layer'],\n",
    "        \"dropout4\": best_params['dropout4'],\n",
    "        \"width_output_layer\": 1,\n",
    "        \"activation\": \"relu\",\n",
    "        \"criterion\": \"Mean Squared Error (MSE) loss\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"adaptive_batching_learning_rate\": True,\n",
    "        \"initial_lr\": best_params['initial_lr'],\n",
    "        \"initial_batch_size\": best_params['initial_batch_size'],\n",
    "        \"max_batch_size\": len(X_train),\n",
    "        \"grad_threshold\": best_params['grad_threshold'],\n",
    "        \"batch_multiplier\": best_params['batch_multiplier'],\n",
    "        \"lr_multiplier\": best_params['lr_multiplier'],\n",
    "        \"grad_threshold_multiplier\": best_params['grad_threshold_multiplier'],\n",
    "        \"lr_min\": best_params['lr_min'],\n",
    "        \"epoch_max\": epoch_max,\n",
    "        \"final_model\": True\n",
    "    }\n",
    "    \n",
    "    _logs.info(f\"Final model parameters:\")\n",
    "    _logs.info(pprint.pformat(params, indent=2, width=80))\n",
    "    \n",
    "    # KFold setup\n",
    "    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Store results for each fold\n",
    "    fold_results = {\n",
    "        'val_mse': [], 'val_rmse': [], 'val_mae': [], 'val_mape': [], 'val_r2': [],\n",
    "        'train_mse': [], 'train_rmse': [], 'train_mae': [], 'train_mape': [], 'train_r2': []\n",
    "    }\n",
    "    \n",
    "    # KFold cross-validation loop\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train)):\n",
    "        _logs.info(f\"\\n--- Fold {fold + 1}/{n_folds} ---\")\n",
    "        \n",
    "        # Create fold-specific train/validation splits\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        y_train_fold = y_train[train_idx]\n",
    "        X_val_fold = X_train[val_idx]\n",
    "        y_val_fold = y_train[val_idx]\n",
    "\n",
    "        # Make it reproducible\n",
    "        SEED = 42\n",
    "        random.seed(SEED)\n",
    "        np.random.seed(SEED)\n",
    "        torch.manual_seed(SEED)\n",
    "        torch.cuda.manual_seed(SEED)\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "        # Initialize model with best parameters\n",
    "        model = FeedforwardNN(\n",
    "            input_size=X_train_fold.shape[1],\n",
    "            width_1st_layer=best_params['width_1st_layer'],\n",
    "            width_2nd_layer=best_params['width_2nd_layer'],\n",
    "            width_3rd_layer=best_params['width_3rd_layer'],\n",
    "            width_4th_layer=best_params['width_4th_layer'],\n",
    "            width_output_layer=1,\n",
    "            dropout1=best_params['dropout1'],\n",
    "            dropout2=best_params['dropout2'],\n",
    "            dropout3=best_params['dropout3'],\n",
    "            dropout4=best_params['dropout4']\n",
    "        )\n",
    "        model.apply(init_weights)\n",
    "\n",
    "        # Setup device\n",
    "        device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "        \n",
    "        # Move data to device\n",
    "        X_train_fold = X_train_fold.to(device)\n",
    "        y_train_fold = y_train_fold.to(device)\n",
    "        X_val_fold = X_val_fold.to(device)\n",
    "        y_val_fold = y_val_fold.to(device)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Initialize adaptive batch trainer with best parameters\n",
    "        adaptive_trainer = GradientAdaptiveBatchingLearning(\n",
    "            initial_batch_size=best_params['initial_batch_size'],\n",
    "            initial_lr=best_params['initial_lr'],\n",
    "            grad_threshold=best_params['grad_threshold'],\n",
    "            batch_multiplier=best_params['batch_multiplier'],\n",
    "            lr_multiplier=best_params['lr_multiplier'],\n",
    "            lr_min=best_params['lr_min'],\n",
    "            max_batch_size=len(X_train_fold)\n",
    "        )\n",
    "        \n",
    "        # Create DataLoaders\n",
    "        train_dataset = TensorDataset(X_train_fold, y_train_fold)\n",
    "        val_dataset = TensorDataset(X_val_fold, y_val_fold)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=best_params['initial_batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=best_params['initial_batch_size'], shuffle=False)\n",
    "        \n",
    "        # Training setup\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=adaptive_trainer.current_lr)\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        trigger_times = 0\n",
    "        min_delta = 0\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        batch_size_history = []\n",
    "        lr_history = []\n",
    "        \n",
    "        # Training loop with progress bar\n",
    "        progress = tqdm(range(epoch_max), desc=f\"Fold {fold+1} Training\")\n",
    "        for epoch in progress:\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            epoch_train_loss = 0.0\n",
    "            num_train_batches = 0\n",
    "            \n",
    "            for batch_X, batch_y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                output = model(batch_X)\n",
    "                loss = criterion(output, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_train_loss += loss.item()\n",
    "                num_train_batches += 1\n",
    "            \n",
    "            avg_train_loss = epoch_train_loss / num_train_batches\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            epoch_val_loss = 0.0\n",
    "            num_val_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_X, batch_y in val_loader:\n",
    "                    val_output = model(batch_X)\n",
    "                    val_loss = criterion(val_output, batch_y)\n",
    "                    epoch_val_loss += val_loss.item()\n",
    "                    num_val_batches += 1\n",
    "            \n",
    "            avg_val_loss = epoch_val_loss / num_val_batches\n",
    "            \n",
    "            # Adaptive batch size and learning rate update\n",
    "            new_batch_size, new_lr = adaptive_trainer.update_params(avg_val_loss, epoch)\n",
    "            \n",
    "            # Update optimizer learning rate if changed\n",
    "            if new_lr != optimizer.param_groups[0]['lr']:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = new_lr\n",
    "            \n",
    "            # Create new dataloader if batch size changed\n",
    "            if new_batch_size != train_loader.batch_size:\n",
    "                train_loader = DataLoader(train_dataset, batch_size=new_batch_size, shuffle=True)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=new_batch_size, shuffle=False)\n",
    "            \n",
    "            # Track history\n",
    "            batch_size_history.append(new_batch_size)\n",
    "            lr_history.append(new_lr)\n",
    "            train_losses.append(avg_train_loss)\n",
    "            val_losses.append(avg_val_loss)\n",
    "            \n",
    "            # Update progress display\n",
    "            with torch.no_grad():\n",
    "                sample_output = model(X_train_fold[:new_batch_size])\n",
    "                sample_rmse = compute_rmse(sample_output, y_train_fold[:new_batch_size])\n",
    "                progress.set_postfix({\n",
    "                    \"Loss\": avg_train_loss, \n",
    "                    \"RMSE\": sample_rmse.item(),\n",
    "                    \"BatchSize\": new_batch_size,\n",
    "                    \"LR\": f\"{new_lr:.6f}\"\n",
    "                })\n",
    "            \n",
    "            # Early stopping logic\n",
    "            if avg_val_loss + min_delta < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                trigger_times = 0\n",
    "            else:\n",
    "                trigger_times += 1\n",
    "                if trigger_times >= patience:\n",
    "                    _logs.info(f\"\\n⏹️ Early stopping at epoch {epoch} — no validation improvement after {patience} epochs.\")\n",
    "                    break\n",
    "            \n",
    "            # Periodic logging\n",
    "            if epoch % 10000 == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    train_output = model(X_train_fold)\n",
    "                    val_output = model(X_val_fold)\n",
    "                    train_loss_full = criterion(train_output, y_train_fold)\n",
    "                    val_loss_full = criterion(val_output, y_val_fold)\n",
    "                    \n",
    "                    rmse = compute_rmse(train_output, y_train_fold)\n",
    "                    mae = compute_mae(train_output, y_train_fold)\n",
    "                    r2 = compute_r2(train_output, y_train_fold)\n",
    "                    val_rmse = compute_rmse(val_output, y_val_fold)\n",
    "                    val_mae = compute_mae(val_output, y_val_fold)\n",
    "                    val_r2 = compute_r2(val_output, y_val_fold)\n",
    "                    \n",
    "                _logs.info(f\"\\nEpoch {epoch}:\")\n",
    "                _logs.info(f\"Train → MSE = {train_loss_full.item():.4f}, RMSE = {rmse.item():.4f}, MAE = {mae.item():.4f}, R² = {r2.item():.4f}\")\n",
    "                _logs.info(f\"Val   → MSE = {val_loss_full.item():.4f}, RMSE = {val_rmse.item():.4f}, MAE = {val_mae.item():.4f}, R² = {val_r2.item():.4f}\")\n",
    "        \n",
    "        # Final evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_output = model(X_train_fold)\n",
    "            val_output = model(X_val_fold)\n",
    "            \n",
    "            # Training metrics\n",
    "            training_mse = criterion(train_output, y_train_fold)\n",
    "            training_rmse = compute_rmse(train_output, y_train_fold)\n",
    "            training_mae = compute_mae(train_output, y_train_fold)\n",
    "            training_mape = compute_mape(train_output, y_train_fold)\n",
    "            training_r2_score = compute_r2(train_output, y_train_fold)\n",
    "        \n",
    "            # Validation metrics\n",
    "            val_mse = criterion(val_output, y_val_fold)\n",
    "            val_rmse = compute_rmse(val_output, y_val_fold)\n",
    "            val_mae = compute_mae(val_output, y_val_fold)\n",
    "            val_mape = compute_mape(val_output, y_val_fold)\n",
    "            val_r2_score = compute_r2(val_output, y_val_fold)\n",
    "            \n",
    "            _logs.info(f\"\\nFold {fold+1} Final Results:\")\n",
    "            _logs.info(f\"Train → MSE = {training_mse.item():.4f}, RMSE = {training_rmse.item():.4f}, MAE = {training_mae.item():.4f}, R² Score = {training_r2_score.item():.4f}\")\n",
    "            _logs.info(f\"Val   → MSE = {val_mse.item():.4f}, RMSE = {val_rmse.item():.4f}, MAE = {val_mae.item():.4f}, R² Score = {val_r2_score.item():.4f}\")\n",
    "\n",
    "        # Store fold results\n",
    "        fold_results['train_mse'].append(training_mse.item())\n",
    "        fold_results['train_rmse'].append(training_rmse.item())\n",
    "        fold_results['train_mae'].append(training_mae.item())\n",
    "        fold_results['train_mape'].append(training_mape.item())\n",
    "        fold_results['train_r2'].append(training_r2_score.item())\n",
    "        \n",
    "        fold_results['val_mse'].append(val_mse.item())\n",
    "        fold_results['val_rmse'].append(val_rmse.item())\n",
    "        fold_results['val_mae'].append(val_mae.item())\n",
    "        fold_results['val_mape'].append(val_mape.item())\n",
    "        fold_results['val_r2'].append(val_r2_score.item())\n",
    "\n",
    "        # Create visualization\n",
    "        start = 100 \n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Loss curves\n",
    "        ax1.plot(range(start, len(train_losses)), train_losses[start:], label='Training Loss', color='blue')\n",
    "        ax1.plot(range(start, len(val_losses)), val_losses[start:], label='Validation Loss', color='orange')\n",
    "        ax1.set_xlabel(\"Epoch\")\n",
    "        ax1.set_ylabel(\"Loss\")\n",
    "        ax1.set_title(f\"Loss Curves - Fold {fold+1}\")\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # Batch size evolution\n",
    "        ax2.plot(batch_size_history, color='green')\n",
    "        ax2.set_xlabel(\"Epoch\")\n",
    "        ax2.set_ylabel(\"Batch Size\")\n",
    "        ax2.set_title(f\"Batch Size Evolution - Fold {fold+1}\")\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        # Learning rate evolution\n",
    "        ax3.plot(lr_history, color='red')\n",
    "        ax3.set_xlabel(\"Epoch\")\n",
    "        ax3.set_ylabel(\"Learning Rate\")\n",
    "        ax3.set_title(f\"Learning Rate Evolution - Fold {fold+1}\")\n",
    "        ax3.grid(True)\n",
    "        \n",
    "        # Validation loss gradient\n",
    "       if len(val_losses) > 50:\n",
    "            val_gradients = np.diff(val_losses)\n",
    "            ax4.plot(val_gradients[-min(10000, len(val_gradients)):], color='orange', alpha=0.7)\n",
    "            ax4.axhline(y=best_params['grad_threshold'], color='red', linestyle='--', \n",
    "                        label=f'Threshold: {best_params[\"grad_threshold\"]}')\n",
    "            ax4.axhline(y=-best_params['grad_threshold'], color='red', linestyle='--')\n",
    "            ax4.set_xlabel(\"Epoch\")\n",
    "            ax4.set_ylabel(\"Validation Loss Gradient\")\n",
    "            ax4.set_title(f\"Recent Validation Loss Gradient - Fold {fold+1}\")\n",
    "            ax4.legend()\n",
    "            ax4.grid(True)\n",
    "    \n",
    "        plt.tight_layout()   \n",
    "        # Log this fold's plot to MLflow immediately\n",
    "        plot_filename = f\"final_fold_{fold+1}_training_plots.png\"\n",
    "        plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Log to MLflow in a separate run for this fold\n",
    "        fold_run_name = f\"FINAL_Fold_{fold+1}_{params['width_1st_layer']}x{params['width_2nd_layer']}x{params['width_3rd_layer']}x{params['width_4th_layer']}\"\n",
    "        with mlflow.start_run(run_name=fold_run_name):\n",
    "            # Log fold-specific parameters\n",
    "            fold_params = params.copy()\n",
    "            fold_params[\"fold\"] = fold + 1\n",
    "            fold_params[\"max_batch_size\"] = len(X_train_fold)\n",
    "            mlflow.log_params(fold_params)\n",
    "            \n",
    "            # Log the plot artifact\n",
    "            mlflow.log_artifact(plot_filename)\n",
    "            \n",
    "        plt.close()  # Close to free memory\n",
    "        os.remove(plot_filename)  # Clean up the file\n",
    "        \n",
    "        # Print summary of adaptive batching\n",
    "        _logs.info(f\"\\n📊 Adaptive Batching Summary - Fold {fold+1}:\")\n",
    "        _logs.info(f\"  Initial batch size: {best_params['initial_batch_size']}\")\n",
    "        _logs.info(f\"  Final batch size: {batch_size_history[-1]}\")\n",
    "        _logs.info(f\"  Initial learning rate: {best_params['initial_lr']:.6f}\")\n",
    "        _logs.info(f\"  Final learning rate: {lr_history[-1]:.6f}\")\n",
    "        _logs.info(f\"  Number of batch size increases: {len(set(batch_size_history)) - 1}\")\n",
    "\n",
    "        # Clean up\n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Compute and log cross-validation summary statistics\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    _logs.info(f\"\\n{'='*60}\")\n",
    "    _logs.info(f\"Final Model Cross-Validation Summary\")\n",
    "    _logs.info(f\"{'='*60}\")\n",
    "\n",
    "    cv_summary = {}\n",
    "    for metric_name, values in fold_results.items():\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        cv_summary[f\"{metric_name}_mean\"] = mean_val\n",
    "        cv_summary[f\"{metric_name}_std\"] = std_val\n",
    "        _logs.info(f\"{metric_name}: {mean_val:.4f} ± {std_val:.4f}\")\n",
    "\n",
    "    # Log cross-validation summary to MLflow\n",
    "    run_name = f\"FINAL_MODEL_CV_SUMMARY_{params['width_1st_layer']}x{params['width_2nd_layer']}x{params['width_3rd_layer']}x{params['width_4th_layer']}\"\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Log best parameters used\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Log all CV summary metrics\n",
    "        for metric_name, metric_value in cv_summary.items():\n",
    "            mlflow.log_metric(metric_name, round(metric_value, 4))\n",
    "        \n",
    "        # Log training time\n",
    "        mlflow.log_metric(\"total_training_time_seconds\", total_time)\n",
    "\n",
    "    _logs.info(f\"\\n⏳ Final model training completed in {total_time:.2f} seconds.\")\n",
    "    \n",
    "    # Clean memory\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return cv_summary\n",
    "##################################################################################################################################################\n",
    "# Step 1: Find best hyperparameters\n",
    "_logs.info(\"Starting hyperparameter optimization...\")\n",
    "study = run_optuna_optimization(\n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    data_file_name=data_file_name,\n",
    "    n_trials=50,\n",
    "    study_name=\"neural_net_optimization\"\n",
    ")\n",
    "# Step 2: Train final model with best parameters\n",
    "_logs.info(\"Training final model with optimized parameters...\")\n",
    "cv_results = train_final_model_with_best_params(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    best_params=study.best_params,\n",
    "    data_file_name=data_file_name\n",
    ")\n",
    "# Access the results\n",
    "_logs.info(f\"Final validation RMSE: {cv_results['val_rmse_mean']:.4f} ± {cv_results['val_rmse_std']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gtx1060_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
