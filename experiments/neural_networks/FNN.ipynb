{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "986ab7cc",
   "metadata": {},
   "source": [
    "**Feedforward Neural Network (FNN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73fc4c9",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebc28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9b27da",
   "metadata": {},
   "source": [
    "Load csv into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f040e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: c:\\Users\\The Winner\\DSI\\customer_purchasing_behaviour\n",
      "Successfully loaded 'Customer_Purchasing_Behaviors.csv' into the DataFrame named df.\n"
     ]
    }
   ],
   "source": [
    "# --- Ensure consistent working directory for data loading ---\n",
    "# This block dynamically sets the current working directory to the Git repository root.\n",
    "# This makes data paths reliable for all collaborators, regardless of where they open the notebook.\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "repo_root = current_dir\n",
    "while not os.path.exists(os.path.join(repo_root, '.git')):\n",
    "    # Move up one directory\n",
    "    parent_dir = os.path.dirname(repo_root)\n",
    "    if parent_dir == repo_root: # Reached filesystem root, .git not found\n",
    "        raise FileNotFoundError(\n",
    "            \"Could not find the .git directory. \"\n",
    "            \"Please ensure you are running this code from within a Git repository.\"\n",
    "        )\n",
    "    repo_root = parent_dir\n",
    "\n",
    "# Change the current working directory if it's not already the repo root\n",
    "if os.getcwd() != repo_root:\n",
    "    os.chdir(repo_root)\n",
    "    print(f\"Working directory set to: {os.getcwd()}\") # Informative print for users\n",
    "\n",
    "\n",
    "# --- Data Loading ---\n",
    "# Path to the data file, relative to the repository root.\n",
    "data_file_name = 'Customer_Purchasing_Behaviors.csv'\n",
    "data_file_path = os.path.join('src', 'data', data_file_name)\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_file_path)\n",
    "    print(f\"Successfully loaded '{data_file_name}' into the DataFrame named df.\")\n",
    "    #print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{data_file_name}' was not found at '{data_file_path}'.\")\n",
    "    print(\"Please ensure it exists in the 'src/data/' folder relative to the repository root.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during data loading: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaad9b8",
   "metadata": {},
   "source": [
    "Prepare data: scale numerical and encode categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9866895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Prepare Inputs\n",
    "\n",
    "# Extract relevant columns\n",
    "numerical_cols = ['age', 'annual_income', 'loyalty_score', 'purchase_frequency']\n",
    "categorical_col = 'region'\n",
    "target_col = 'purchase_amount'\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_num = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Encode categorical feature\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_cat = encoder.fit_transform(df[[categorical_col]])\n",
    "\n",
    "# Create DataFrames with distinct column names\n",
    "num_df = pd.DataFrame(X_num, columns=numerical_cols)\n",
    "cat_columns = encoder.get_feature_names_out([categorical_col])\n",
    "cat_df = pd.DataFrame(X_cat, columns=cat_columns)\n",
    "\n",
    "# Combine safely\n",
    "combined_df = pd.concat([num_df, cat_df], axis=1)\n",
    "\n",
    "# Convert to torch tensor\n",
    "X_combined = torch.tensor(combined_df.values, dtype=torch.float32)\n",
    "\n",
    "# Target variable\n",
    "y = torch.tensor(df[target_col].values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e702375f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Losses: MSE = 202057.7500, RMSE = 449.5083, MAE = 428.2060\n",
      "Epoch 1000: Losses: MSE = 99.3161, RMSE = 9.9657, MAE = 7.2834\n",
      "Epoch 2000: Losses: MSE = 92.3433, RMSE = 9.6095, MAE = 7.0018\n",
      "Epoch 3000: Losses: MSE = 91.5156, RMSE = 9.5664, MAE = 6.9330\n",
      "Epoch 4000: Losses: MSE = 91.4174, RMSE = 9.5612, MAE = 6.9101\n",
      "Epoch 5000: Losses: MSE = 91.4091, RMSE = 9.5608, MAE = 6.9026\n",
      "Epoch 6000: Losses: MSE = 91.4084, RMSE = 9.5608, MAE = 6.9005\n",
      "Epoch 7000: Losses: MSE = 91.4087, RMSE = 9.5608, MAE = 6.9002\n",
      "Epoch 8000: Losses: MSE = 91.4993, RMSE = 9.5655, MAE = 6.8886\n",
      "Epoch 9000: Losses: MSE = 91.4085, RMSE = 9.5608, MAE = 6.9002\n",
      "Epoch 10000: Losses: MSE = 91.4086, RMSE = 9.5608, MAE = 6.9001\n",
      "Test:         Losses: MSE = 114.2079, RMSE = 10.6868, MAE = 7.4063\n"
     ]
    }
   ],
   "source": [
    "# Make it reproducible\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)                 # Python random\n",
    "np.random.seed(SEED)              # NumPy\n",
    "torch.manual_seed(SEED)           # CPU\n",
    "torch.cuda.manual_seed(SEED)      # GPU\n",
    "torch.cuda.manual_seed_all(SEED)  # Multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Define the Neural Network Model\n",
    "\n",
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(FeedforwardNN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = FeedforwardNN(input_size=X_train.shape[1])\n",
    "def init_weights(m):\n",
    "    '''Make the weight initialization reproducible'''\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)  # still uses seed\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias, 0.01)\n",
    "model.apply(init_weights)      \n",
    "\n",
    "# Make GPU work\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Move data to device\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Training with MSE & Logging RMSE, MAE \n",
    "\n",
    "# Define RMSE metric (no need to backprop through it)\n",
    "def compute_rmse(predictions, targets):\n",
    "    return torch.sqrt(F.mse_loss(predictions, targets))\n",
    "def compute_mae(predictions, targets):\n",
    "    return torch.mean(torch.abs(predictions - targets))\n",
    "\n",
    "# Train the Model\n",
    "\n",
    "criterion = nn.MSELoss()            # Mean Squared Error (MSE) loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "for epoch in range(10001):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, y_train)       # MSE for optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Log RMSE & MAE every N epoch\n",
    "    if epoch % 1000 == 0:\n",
    "        rmse = compute_rmse(output, y_train)\n",
    "        mae = compute_mae(output, y_train)\n",
    "        print(f\"Epoch {epoch}: Losses: MSE = {loss.item():.4f}, RMSE = {rmse.item():.4f}, MAE = {mae.item():.4f}\")\n",
    "\n",
    "# Evaluate the Model\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "    test_loss = criterion(predictions, y_test)\n",
    "    test_rmse = compute_rmse(predictions, y_test)\n",
    "    test_mae = compute_mae(predictions, y_test)\n",
    "    print(f\"Test:        Losses: MSE = {test_loss.item():.4f}, RMSE = {test_rmse.item():.4f}, MAE = {test_mae.item():.4f}\")\n",
    "\n",
    "# Clean memory in case we want to run this cell again without running the whole notebook\n",
    "# remove references to GPU objects \n",
    "del model\n",
    "# Invoke garbage collector\n",
    "gc.collect()\n",
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gtx1060_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
