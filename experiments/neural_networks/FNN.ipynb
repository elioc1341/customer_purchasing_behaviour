{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "986ab7cc",
   "metadata": {},
   "source": [
    "**Feedforward Neural Network (FNN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73fc4c9",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7339577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9b27da",
   "metadata": {},
   "source": [
    "Load csv into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f040e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: c:\\Users\\The Winner\\DSI\\customer_purchasing_behaviour\n",
      "Successfully loaded 'Customer_Purchasing_Behaviors.csv' into the DataFrame named df.\n"
     ]
    }
   ],
   "source": [
    "# --- Ensure consistent working directory for data loading ---\n",
    "# This block dynamically sets the current working directory to the Git repository root.\n",
    "# This makes data paths reliable for all collaborators, regardless of where they open the notebook.\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "repo_root = current_dir\n",
    "while not os.path.exists(os.path.join(repo_root, '.git')):\n",
    "    # Move up one directory\n",
    "    parent_dir = os.path.dirname(repo_root)\n",
    "    if parent_dir == repo_root: # Reached filesystem root, .git not found\n",
    "        raise FileNotFoundError(\n",
    "            \"Could not find the .git directory. \"\n",
    "            \"Please ensure you are running this code from within a Git repository.\"\n",
    "        )\n",
    "    repo_root = parent_dir\n",
    "\n",
    "# Change the current working directory if it's not already the repo root\n",
    "if os.getcwd() != repo_root:\n",
    "    os.chdir(repo_root)\n",
    "    print(f\"Working directory set to: {os.getcwd()}\") # Informative print for users\n",
    "\n",
    "\n",
    "# --- Data Loading ---\n",
    "# Path to the data file, relative to the repository root.\n",
    "data_file_name = 'Customer_Purchasing_Behaviors.csv'\n",
    "data_file_path = os.path.join('data', 'raw', data_file_name)\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_file_path)\n",
    "    print(f\"Successfully loaded '{data_file_name}' into the DataFrame named df.\")\n",
    "    #print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{data_file_name}' was not found at '{data_file_path}'.\")\n",
    "    print(\"Please ensure it exists in the 'data/raw/' folder relative to the repository root.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during data loading: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaad9b8",
   "metadata": {},
   "source": [
    "Prepare data: scale numerical and encode categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9866895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Prepare Inputs\n",
    "\n",
    "# Extract relevant columns\n",
    "numerical_cols = ['age', 'annual_income', 'loyalty_score', 'purchase_frequency']\n",
    "categorical_col = 'region'\n",
    "target_col = 'purchase_amount'\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_num = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Encode categorical feature\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_cat = encoder.fit_transform(df[[categorical_col]])\n",
    "\n",
    "# Create DataFrames with distinct column names\n",
    "num_df = pd.DataFrame(X_num, columns=numerical_cols)\n",
    "cat_columns = encoder.get_feature_names_out([categorical_col])\n",
    "cat_df = pd.DataFrame(X_cat, columns=cat_columns)\n",
    "\n",
    "# Combine safely\n",
    "combined_df = pd.concat([num_df, cat_df], axis=1)\n",
    "\n",
    "# Convert to torch tensor\n",
    "X_combined = torch.tensor(combined_df.values, dtype=torch.float32)\n",
    "\n",
    "# Target variable\n",
    "y = torch.tensor(df[target_col].values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split into Train + Validation, and Test (80% train+val, 20% test)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e702375f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "Train → MSE = 204984.8125, RMSE = 452.7525, MAE = 433.7315, R² = -11.1192\n",
      "Val   → MSE = 193116.9688, RMSE = 439.4507, MAE = 411.5416, R² = -7.1000\n",
      "\n",
      "⏹️ Early stopping at epoch 82 — no validation improvement after 10 epochs.\n",
      "\n",
      "Final Test Evaluation:\n",
      "MSE = 16975.2461, RMSE = 130.2891, MAE = 106.9194, R² Score = 0.2441\n"
     ]
    }
   ],
   "source": [
    "# Make it reproducible\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)                 # Python random\n",
    "np.random.seed(SEED)              # NumPy\n",
    "torch.manual_seed(SEED)           # CPU\n",
    "torch.cuda.manual_seed(SEED)      # GPU\n",
    "torch.cuda.manual_seed_all(SEED)  # Multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Define the Neural Network Model\n",
    "\n",
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(FeedforwardNN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = FeedforwardNN(input_size=X_train.shape[1])\n",
    "def init_weights(m):\n",
    "    '''Make the weight initialization reproducible'''\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)  # still uses seed\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias, 0.01)\n",
    "model.apply(init_weights)      \n",
    "\n",
    "# Make GPU work\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "# Move data to device\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_val = X_val.to(device)\n",
    "y_val = y_val.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Training with MSE & Logging RMSE, MAE \n",
    "\n",
    "# Metrics\n",
    "def compute_rmse(predictions, targets):\n",
    "    return torch.sqrt(F.mse_loss(predictions, targets))\n",
    "def compute_mae(predictions, targets):\n",
    "    return torch.mean(torch.abs(predictions - targets))\n",
    "def compute_r2(predictions, targets):\n",
    "    ss_res = torch.sum((targets - predictions) ** 2)\n",
    "    ss_tot = torch.sum((targets - torch.mean(targets)) ** 2)\n",
    "    return 1 - ss_res / ss_tot\n",
    "\n",
    "# Training + Early Stopping\n",
    "criterion = nn.MSELoss()   # Mean Squared Error (MSE) loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "trigger_times = 0\n",
    "\n",
    "for epoch in range(10001):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, y_train)      # MSE for optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_output = model(X_val)\n",
    "        val_loss = criterion(val_output, y_val)\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss.item() < best_val_loss:\n",
    "        best_val_loss = val_loss.item()\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(f\"\\n⏹️ Early stopping at epoch {epoch} — no validation improvement after {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "    if epoch % 100 == 0 or trigger_times == patience:\n",
    "        rmse = compute_rmse(output, y_train)\n",
    "        mae = compute_mae(output, y_train)\n",
    "        r2 = compute_r2(output, y_train)\n",
    "        val_rmse = compute_rmse(val_output, y_val)\n",
    "        val_mae = compute_mae(val_output, y_val)\n",
    "        val_r2 = compute_r2(val_output, y_val)\n",
    "        print(f\"Epoch {epoch}:\")\n",
    "        print(f\"Train → MSE = {loss.item():.4f}, RMSE = {rmse.item():.4f}, MAE = {mae.item():.4f}, R² = {r2.item():.4f}\")\n",
    "        print(f\"Val   → MSE = {val_loss.item():.4f}, RMSE = {val_rmse.item():.4f}, MAE = {val_mae.item():.4f}, R² = {val_r2.item():.4f}\")\n",
    "\n",
    "# Final Evaluation on Test Set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "    test_loss = criterion(predictions, y_test)\n",
    "    test_rmse = compute_rmse(predictions, y_test)\n",
    "    test_mae = compute_mae(predictions, y_test)\n",
    "    test_r2 = compute_r2(predictions, y_test)\n",
    "    print(f\"\\nFinal Test Evaluation:\")\n",
    "    print(f\"MSE = {test_loss.item():.4f}, RMSE = {test_rmse.item():.4f}, MAE = {test_mae.item():.4f}, R² Score = {test_r2.item():.4f}\")\n",
    "\n",
    "# Clean memory in case we want to run this cell again without running the whole notebook\n",
    "# remove references to GPU objects \n",
    "del model\n",
    "# Invoke garbage collector\n",
    "gc.collect()\n",
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Final Test Evaluation:\n",
    "# MSE = 120.3766, RMSE = 10.9716, MAE = 7.7399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c87f2f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏳ Training completed in 2.97 seconds.\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\n⏳ Training completed in {elapsed_time:.2f} seconds.\")\n",
    "# GPU: ⏳ Training completed in 16.07 seconds.\n",
    "# CPU: ⏳ Training completed in 14.11 seconds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gtx1060_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
