{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "986ab7cc",
   "metadata": {},
   "source": [
    "**Feedforward Neural Network (FNN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73fc4c9",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebc28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a674b5",
   "metadata": {},
   "source": [
    "Classes / Functions used below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6960d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient-Based Adaptive Batch Size Class\n",
    "class GradientAdaptiveBatchingLearning:\n",
    "    def __init__(self, initial_batch_size=16, initial_lr=0.001, \n",
    "                 grad_threshold=0.01, batch_multiplier=1.4, lr_multiplier=0.8, lr_min=0.0005, max_batch_size=142):\n",
    "        self.current_batch_size = initial_batch_size\n",
    "        self.current_lr = initial_lr\n",
    "        self.grad_threshold = grad_threshold\n",
    "        self.batch_multiplier = batch_multiplier\n",
    "        self.lr_multiplier = lr_multiplier\n",
    "        self.lr_min = lr_min\n",
    "        self.max_batch_size = max_batch_size  # Will be set dynamically to len(X_train)\n",
    "        self.loss_history = []\n",
    "        self.update_count = 0\n",
    "        \n",
    "    def update_params(self, current_loss, epoch):\n",
    "        self.loss_history.append(current_loss)\n",
    "        \n",
    "        # Need at least 5 epochs of history for gradient calculation\n",
    "        if len(self.loss_history) >= 5:\n",
    "            # Calculate gradient (first derivative) over recent losses\n",
    "            recent_losses = self.loss_history[-5:]\n",
    "            gradient = np.mean(np.diff(recent_losses))\n",
    "            \n",
    "            # Additional stability check: don't update too frequently\n",
    "            epochs_since_update = len(self.loss_history) - self.update_count\n",
    "            \n",
    "            # If gradient is small (slow improvement) and enough time passed\n",
    "            if abs(gradient) < self.grad_threshold and epochs_since_update >= 10:\n",
    "                new_batch_size = min(\n",
    "                    int(self.current_batch_size * self.batch_multiplier), \n",
    "                    self.max_batch_size\n",
    "                )\n",
    "                # Decrease learning rate when increasing batch size\n",
    "                lr_scaling = self.lr_multiplier  # self.current_batch_size / new_batch_size\n",
    "                self.current_lr = max(\n",
    "                    self.current_lr*lr_scaling, \n",
    "                    self.lr_min\n",
    "                )\n",
    "                self.current_batch_size = new_batch_size\n",
    "                self.update_count = len(self.loss_history)\n",
    "                # Gradient Threshold updated\n",
    "                self.grad_threshold = self.grad_threshold * 0.25\n",
    "                \n",
    "                print(f\"Epoch {epoch}: Gradient = {gradient:.6f} < {self.grad_threshold}\")\n",
    "                print(f\"  → Increased batch size: {int(self.current_batch_size/self.batch_multiplier)} → {self.current_batch_size}\")\n",
    "                print(f\"  → Decreased learning rate: {self.current_lr/lr_scaling:.6f} → {self.current_lr:.6f}\")\n",
    "                    \n",
    "        return self.current_batch_size, self.current_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9b27da",
   "metadata": {},
   "source": [
    "Load csv into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f040e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: c:\\Users\\The Winner\\DSI\\customer_purchasing_behaviour\n",
      "Successfully loaded 'df_eng_customer_purchasing_features.csv' into the DataFrame named df.\n"
     ]
    }
   ],
   "source": [
    "# --- Ensure consistent working directory for data loading ---\n",
    "# This block dynamically sets the current working directory to the Git repository root.\n",
    "# This makes data paths reliable for all collaborators, regardless of where they open the notebook.\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "repo_root = current_dir\n",
    "while not os.path.exists(os.path.join(repo_root, '.git')):\n",
    "    # Move up one directory\n",
    "    parent_dir = os.path.dirname(repo_root)\n",
    "    if parent_dir == repo_root: # Reached filesystem root, .git not found\n",
    "        raise FileNotFoundError(\n",
    "            \"Could not find the .git directory. \"\n",
    "            \"Please ensure you are running this code from within a Git repository.\"\n",
    "        )\n",
    "    repo_root = parent_dir\n",
    "\n",
    "# Change the current working directory if it's not already the repo root\n",
    "if os.getcwd() != repo_root:\n",
    "    os.chdir(repo_root)\n",
    "    print(f\"Working directory set to: {os.getcwd()}\") # Informative print for users\n",
    "\n",
    "\n",
    "# --- Data Loading ---\n",
    "# Path to the data file, relative to the repository root.\n",
    "data_file_name = 'df_eng_customer_purchasing_features.csv'\n",
    "data_file_path = os.path.join('data', 'processed', data_file_name)\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_file_path)\n",
    "    print(f\"Successfully loaded '{data_file_name}' into the DataFrame named df.\")\n",
    "    #print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{data_file_name}' was not found at '{data_file_path}'.\")\n",
    "    print(\"Please ensure it exists in the 'data/processed/' folder relative to the repository root.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during data loading: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e15a58c",
   "metadata": {},
   "source": [
    "Split the data between train portion and a holdout portion, split holdout for validation and test  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9696b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Hold out 20% of the dataset (to become val + test)\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(df.drop(['purchase_amount', 'log_purchase_amount'], axis=1), df[['purchase_amount', 'log_purchase_amount']], test_size=0.2, random_state=42)\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "# Step 2: Split holdout into 10% validation and 10% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_holdout, y_holdout, test_size=0.5, random_state=42)\n",
    "df_val = pd.concat([X_val, y_val], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaad9b8",
   "metadata": {},
   "source": [
    "Prepare TRAIN data: scale numerical and encode categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9866895",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.copy() \n",
    "\n",
    "# Preprocessing: Prepare Inputs\n",
    "\n",
    "# Extract relevant columns\n",
    "numerical_cols = ['age', 'annual_income', 'loyalty_score', 'purchase_frequency', 'log_annual_income', 'log_purchase_frequency']\n",
    "categorical_cols = ['region_grouped']\n",
    "target_col = 'purchase_amount'\n",
    "target_col_log = 'log_purchase_amount'\n",
    "\n",
    "# Filter to only use columns that actually exist\n",
    "existing_numerical_cols = [col for col in numerical_cols if col in df.columns]\n",
    "existing_categorical_cols = [col for col in categorical_cols if col in df.columns]\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_num = scaler.fit_transform(df[existing_numerical_cols])\n",
    "\n",
    "# Encode categorical feature\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_cat = encoder.fit_transform(df[existing_categorical_cols])\n",
    "\n",
    "# Create DataFrames with distinct column names\n",
    "num_df = pd.DataFrame(X_num, columns=existing_numerical_cols)\n",
    "cat_columns = encoder.get_feature_names_out(existing_categorical_cols)\n",
    "cat_df = pd.DataFrame(X_cat, columns=cat_columns)\n",
    "\n",
    "# Combine safely\n",
    "combined_df = pd.concat([num_df, cat_df], axis=1)\n",
    "\n",
    "# Convert to torch tensor\n",
    "X_train = torch.tensor(combined_df.values, dtype=torch.float32)\n",
    "\n",
    "# Target variable\n",
    "y_train = torch.tensor(df[target_col].values, dtype=torch.float32).view(-1, 1)\n",
    "y_train_log = torch.tensor(df[target_col_log].values, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e94e6",
   "metadata": {},
   "source": [
    "Prepare VAL data: scale numerical and encode categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b70be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_val.copy() \n",
    "\n",
    "# Preprocessing: Prepare Inputs\n",
    "\n",
    "# Extract relevant columns\n",
    "numerical_cols = ['age', 'annual_income', 'loyalty_score', 'purchase_frequency', 'log_annual_income', 'log_purchase_frequency']\n",
    "categorical_cols = ['region_grouped']\n",
    "target_col = 'purchase_amount'\n",
    "target_col_log = 'log_purchase_amount'\n",
    "\n",
    "# Filter to only use columns that actually exist\n",
    "existing_numerical_cols = [col for col in numerical_cols if col in df.columns]\n",
    "existing_categorical_cols = [col for col in categorical_cols if col in df.columns]\n",
    "\n",
    "# Scale numerical features\n",
    "X_num = scaler.transform(df[existing_numerical_cols])\n",
    "\n",
    "# Encode categorical feature\n",
    "X_cat = encoder.transform(df[existing_categorical_cols])\n",
    "\n",
    "# Create DataFrames with distinct column names\n",
    "num_df = pd.DataFrame(X_num, columns=existing_numerical_cols)\n",
    "cat_columns = encoder.get_feature_names_out(existing_categorical_cols)\n",
    "cat_df = pd.DataFrame(X_cat, columns=cat_columns)\n",
    "\n",
    "# Combine safely\n",
    "combined_df = pd.concat([num_df, cat_df], axis=1)\n",
    "\n",
    "# Convert to torch tensor\n",
    "X_val = torch.tensor(combined_df.values, dtype=torch.float32)\n",
    "\n",
    "# Target variable\n",
    "y_val = torch.tensor(df[target_col].values, dtype=torch.float32).view(-1, 1)\n",
    "y_val_log = torch.tensor(df[target_col_log].values, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5a34c",
   "metadata": {},
   "source": [
    "Prepare TEST data: scale numerical and encode categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbaa5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_test.copy() \n",
    "\n",
    "# Preprocessing: Prepare Inputs\n",
    "\n",
    "# Extract relevant columns\n",
    "numerical_cols = ['age', 'annual_income', 'loyalty_score', 'purchase_frequency', 'log_annual_income', 'log_purchase_frequency']\n",
    "categorical_cols = ['region_grouped']\n",
    "target_col = 'purchase_amount'\n",
    "target_col_log = 'log_purchase_amount'\n",
    "\n",
    "# Filter to only use columns that actually exist\n",
    "existing_numerical_cols = [col for col in numerical_cols if col in df.columns]\n",
    "existing_categorical_cols = [col for col in categorical_cols if col in df.columns]\n",
    "\n",
    "# Scale numerical features\n",
    "X_num = scaler.transform(df[existing_numerical_cols])\n",
    "\n",
    "# Encode categorical feature\n",
    "X_cat = encoder.transform(df[existing_categorical_cols])\n",
    "\n",
    "# Create DataFrames with distinct column names\n",
    "num_df = pd.DataFrame(X_num, columns=existing_numerical_cols)\n",
    "cat_columns = encoder.get_feature_names_out(existing_categorical_cols)\n",
    "cat_df = pd.DataFrame(X_cat, columns=cat_columns)\n",
    "\n",
    "# Combine safely\n",
    "combined_df = pd.concat([num_df, cat_df], axis=1)\n",
    "\n",
    "# Convert to torch tensor\n",
    "X_test = torch.tensor(combined_df.values, dtype=torch.float32)\n",
    "\n",
    "# Target variable\n",
    "y_test = torch.tensor(df[target_col].values, dtype=torch.float32).view(-1, 1)\n",
    "y_test_log = torch.tensor(df[target_col_log].values, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d7b4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "  Train: (190, 190, torch.Size([190, 15]), torch.Size([190, 1])) (will be max batch size)\n",
      "  Validation: (24, 24, torch.Size([24, 15]), torch.Size([24, 1]))\n",
      "  Test: (24, 24, torch.Size([24, 15]), torch.Size([24, 1]))\n"
     ]
    }
   ],
   "source": [
    "# Print dataset sizes and set max batch sizes\n",
    "print(f\"Dataset sizes:\")\n",
    "print(f\"  Train: {len(X_train), len(y_train), X_train.shape, y_train.shape} (will be max batch size)\")\n",
    "print(f\"  Validation: {len(X_val), len(y_val), X_val.shape, y_val.shape}\")\n",
    "print(f\"  Test: {len(X_test), len(y_test), X_test.shape, y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b52f03",
   "metadata": {},
   "source": [
    "Run Model and log it in MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e702375f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_dotenv() returned: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40562a54e694f609d4f48cc3c7e3d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "Train → MSE = 199697.1406, RMSE = 446.8748, MAE = 425.2408, R² = -9.6480\n",
      "Val   → MSE = 187099.4219, RMSE = 432.5499, MAE = 400.7163, R² = -6.1030\n",
      "Epoch 53: Gradient = 0.043240 < 0.05\n",
      "  → Increased batch size: 16 → 32\n",
      "  → Decreased learning rate: 0.005000 → 0.002500\n",
      "Epoch 63: Gradient = -0.011280 < 0.05\n",
      "  → Increased batch size: 32 → 64\n",
      "  → Decreased learning rate: 0.002500 → 0.001250\n",
      "Epoch 73: Gradient = -0.003468 < 0.05\n",
      "  → Increased batch size: 64 → 128\n",
      "  → Decreased learning rate: 0.001250 → 0.000625\n",
      "Epoch 83: Gradient = -0.001742 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 93: Gradient = -0.000632 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 103: Gradient = -0.000042 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 113: Gradient = -0.000093 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 123: Gradient = -0.000367 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 133: Gradient = -0.000580 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 143: Gradient = -0.000632 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 153: Gradient = -0.000645 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 163: Gradient = -0.000575 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 173: Gradient = -0.000569 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 183: Gradient = -0.000570 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 193: Gradient = -0.000551 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 203: Gradient = -0.000594 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 213: Gradient = -0.000609 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 223: Gradient = -0.000594 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 233: Gradient = -0.000595 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 243: Gradient = -0.000608 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 253: Gradient = -0.000625 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 263: Gradient = -0.000634 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 273: Gradient = -0.000593 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 283: Gradient = -0.000589 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 293: Gradient = -0.000597 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 303: Gradient = -0.000551 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 313: Gradient = -0.000551 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 323: Gradient = -0.000536 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 333: Gradient = -0.000566 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 343: Gradient = -0.000597 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 353: Gradient = -0.000597 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 363: Gradient = -0.000612 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 373: Gradient = -0.000589 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 383: Gradient = -0.000592 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 393: Gradient = -0.000617 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 403: Gradient = -0.000631 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 413: Gradient = -0.000598 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 423: Gradient = -0.000588 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 433: Gradient = -0.000631 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 443: Gradient = -0.000620 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 453: Gradient = -0.000584 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 463: Gradient = -0.000614 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 473: Gradient = -0.000634 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 483: Gradient = -0.000588 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 493: Gradient = -0.000617 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 503: Gradient = -0.000609 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 513: Gradient = -0.000587 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 523: Gradient = -0.000669 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 533: Gradient = -0.000600 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 543: Gradient = -0.000635 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 553: Gradient = -0.000620 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 563: Gradient = -0.000586 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 573: Gradient = -0.000620 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 583: Gradient = -0.000593 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 593: Gradient = -0.000580 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 603: Gradient = -0.000628 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 613: Gradient = -0.000616 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 623: Gradient = -0.000621 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 633: Gradient = -0.000622 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 643: Gradient = -0.000620 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 653: Gradient = -0.000632 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 663: Gradient = -0.000623 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 673: Gradient = -0.000614 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 683: Gradient = -0.000653 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 693: Gradient = -0.000590 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 703: Gradient = -0.000616 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 713: Gradient = -0.000603 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 723: Gradient = -0.000609 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 733: Gradient = -0.000634 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 743: Gradient = -0.000591 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 753: Gradient = -0.000650 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 763: Gradient = -0.000622 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 773: Gradient = -0.000630 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 783: Gradient = -0.000623 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 793: Gradient = -0.000644 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 803: Gradient = -0.000610 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 813: Gradient = -0.000611 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 823: Gradient = -0.000577 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 833: Gradient = -0.000584 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 843: Gradient = -0.000591 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 853: Gradient = -0.000635 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 863: Gradient = -0.000627 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 873: Gradient = -0.000636 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 883: Gradient = -0.000655 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 893: Gradient = -0.000653 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 903: Gradient = -0.000654 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 913: Gradient = -0.000657 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 923: Gradient = -0.000672 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 933: Gradient = -0.000623 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 943: Gradient = -0.000621 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 953: Gradient = -0.000627 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 963: Gradient = -0.000644 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 973: Gradient = -0.000629 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 983: Gradient = -0.000609 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 993: Gradient = -0.000606 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1003: Gradient = -0.000612 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1013: Gradient = -0.000616 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1023: Gradient = -0.000647 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1033: Gradient = -0.000592 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1043: Gradient = -0.000573 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1053: Gradient = -0.000599 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1063: Gradient = -0.000627 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1073: Gradient = -0.000538 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1083: Gradient = -0.000550 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1093: Gradient = -0.000565 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1103: Gradient = -0.000594 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1113: Gradient = -0.000588 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1123: Gradient = -0.000599 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1133: Gradient = -0.000592 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1143: Gradient = -0.000576 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1153: Gradient = -0.000620 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1163: Gradient = -0.000572 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1173: Gradient = -0.000601 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1183: Gradient = -0.000580 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1193: Gradient = -0.000564 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1203: Gradient = -0.000586 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1213: Gradient = -0.000603 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1223: Gradient = -0.000590 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1233: Gradient = -0.000592 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1243: Gradient = -0.000596 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1253: Gradient = -0.000592 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1263: Gradient = -0.000584 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1273: Gradient = -0.000574 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1283: Gradient = -0.000596 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1293: Gradient = -0.000584 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1303: Gradient = -0.000577 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1313: Gradient = -0.000595 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1323: Gradient = -0.000588 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1333: Gradient = -0.000590 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1343: Gradient = -0.000574 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1353: Gradient = -0.000588 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1363: Gradient = -0.000563 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1373: Gradient = -0.000573 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1383: Gradient = -0.000591 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1393: Gradient = -0.000573 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1403: Gradient = -0.000562 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1413: Gradient = -0.000590 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1423: Gradient = -0.000585 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1433: Gradient = -0.000591 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1443: Gradient = -0.000583 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1453: Gradient = -0.000586 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1463: Gradient = -0.000571 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1473: Gradient = -0.000586 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1483: Gradient = -0.000579 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1493: Gradient = -0.000583 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1503: Gradient = -0.000578 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1513: Gradient = -0.000582 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1523: Gradient = -0.000588 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1533: Gradient = -0.000559 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1543: Gradient = -0.000593 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1553: Gradient = -0.000585 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1563: Gradient = -0.000582 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1573: Gradient = -0.000585 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1583: Gradient = -0.000588 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1593: Gradient = -0.000573 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1603: Gradient = -0.000589 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1613: Gradient = -0.000583 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1623: Gradient = -0.000578 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1633: Gradient = -0.000588 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1643: Gradient = -0.000586 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1653: Gradient = -0.000578 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1663: Gradient = -0.000586 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1673: Gradient = -0.000590 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1683: Gradient = -0.000580 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1693: Gradient = -0.000589 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1703: Gradient = -0.000604 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1713: Gradient = -0.000594 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1723: Gradient = -0.000594 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1733: Gradient = -0.000580 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1743: Gradient = -0.000581 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1753: Gradient = -0.000586 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1763: Gradient = -0.000584 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1773: Gradient = -0.000606 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1783: Gradient = -0.000603 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1793: Gradient = -0.000604 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1803: Gradient = -0.000591 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1813: Gradient = -0.000593 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1823: Gradient = -0.000599 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1833: Gradient = -0.000586 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1843: Gradient = -0.000597 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1853: Gradient = -0.000596 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1863: Gradient = -0.000590 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1873: Gradient = -0.000596 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1883: Gradient = -0.000586 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1893: Gradient = -0.000594 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1903: Gradient = -0.000592 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1913: Gradient = -0.000609 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1923: Gradient = -0.000595 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1933: Gradient = -0.000601 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1943: Gradient = -0.000589 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1953: Gradient = -0.000599 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1963: Gradient = -0.000595 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1973: Gradient = -0.000590 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1983: Gradient = -0.000596 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 1993: Gradient = -0.000589 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2003: Gradient = -0.000591 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2013: Gradient = -0.000582 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2023: Gradient = -0.000609 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2033: Gradient = -0.000596 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2043: Gradient = -0.000595 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2053: Gradient = -0.000597 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2063: Gradient = -0.000605 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2073: Gradient = -0.000595 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2083: Gradient = -0.000603 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2093: Gradient = -0.000606 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2103: Gradient = -0.000590 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2113: Gradient = -0.000601 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2123: Gradient = -0.000588 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2133: Gradient = -0.000598 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2143: Gradient = -0.000602 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2153: Gradient = -0.000594 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2163: Gradient = -0.000606 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2173: Gradient = -0.000593 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2183: Gradient = -0.000606 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2193: Gradient = -0.000601 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2203: Gradient = -0.000590 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2213: Gradient = -0.000594 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2223: Gradient = -0.000601 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2233: Gradient = -0.000613 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2243: Gradient = -0.000587 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2253: Gradient = -0.000595 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2263: Gradient = -0.000607 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2273: Gradient = -0.000599 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2283: Gradient = -0.000597 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2293: Gradient = -0.000616 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2303: Gradient = -0.000599 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2313: Gradient = -0.000596 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2323: Gradient = -0.000588 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2333: Gradient = -0.000593 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2343: Gradient = -0.000590 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2353: Gradient = -0.000589 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2363: Gradient = -0.000609 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2373: Gradient = -0.000604 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2383: Gradient = -0.000600 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2393: Gradient = -0.000600 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2403: Gradient = -0.000593 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2413: Gradient = -0.000603 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2423: Gradient = -0.000608 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2433: Gradient = -0.000614 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2443: Gradient = -0.000611 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2453: Gradient = -0.000610 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2463: Gradient = -0.000610 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2473: Gradient = -0.000598 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2483: Gradient = -0.000609 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2493: Gradient = -0.000602 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2503: Gradient = -0.000595 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2513: Gradient = -0.000594 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2523: Gradient = -0.000598 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2533: Gradient = -0.000602 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2543: Gradient = -0.000599 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2553: Gradient = -0.000600 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2563: Gradient = -0.000601 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2573: Gradient = -0.000593 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2583: Gradient = -0.000603 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2593: Gradient = -0.000590 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2603: Gradient = -0.000603 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2613: Gradient = -0.000610 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2623: Gradient = -0.000603 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2633: Gradient = -0.000590 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2643: Gradient = -0.000605 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2653: Gradient = -0.000601 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2663: Gradient = -0.000605 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2673: Gradient = -0.000597 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2683: Gradient = -0.000611 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2693: Gradient = -0.000597 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2703: Gradient = -0.000553 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2713: Gradient = -0.000615 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2723: Gradient = -0.000569 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2733: Gradient = -0.000595 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2743: Gradient = -0.000574 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2753: Gradient = -0.000584 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2763: Gradient = -0.000584 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2773: Gradient = -0.000571 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2783: Gradient = -0.000578 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2793: Gradient = -0.000572 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2803: Gradient = -0.000593 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2813: Gradient = -0.000592 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2823: Gradient = -0.000589 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2833: Gradient = -0.000576 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2843: Gradient = -0.000578 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2853: Gradient = -0.000590 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2863: Gradient = -0.000591 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2873: Gradient = -0.000571 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2883: Gradient = -0.000568 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2893: Gradient = -0.000577 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2903: Gradient = -0.000577 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2913: Gradient = -0.000575 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2923: Gradient = -0.000575 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2933: Gradient = -0.000578 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2943: Gradient = -0.000569 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2953: Gradient = -0.000579 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2963: Gradient = -0.000570 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2973: Gradient = -0.000570 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2983: Gradient = -0.000568 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 2993: Gradient = -0.000563 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3003: Gradient = -0.000551 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3013: Gradient = -0.000569 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3023: Gradient = -0.000563 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3033: Gradient = -0.000565 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3043: Gradient = -0.000560 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3053: Gradient = -0.000568 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3063: Gradient = -0.000567 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3073: Gradient = -0.000563 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3083: Gradient = -0.000549 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3093: Gradient = -0.000571 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3103: Gradient = -0.000563 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3113: Gradient = -0.000572 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3123: Gradient = -0.000573 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3133: Gradient = -0.000551 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3143: Gradient = -0.000551 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3153: Gradient = -0.000549 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3163: Gradient = -0.000565 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3173: Gradient = -0.000547 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3183: Gradient = -0.000573 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3193: Gradient = -0.000558 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3203: Gradient = -0.000544 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3213: Gradient = -0.000546 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3223: Gradient = -0.000554 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3233: Gradient = -0.000548 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3243: Gradient = -0.000557 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3253: Gradient = -0.000551 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3263: Gradient = -0.000542 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3273: Gradient = -0.000562 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3283: Gradient = -0.000548 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3293: Gradient = -0.000550 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3303: Gradient = -0.000554 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3313: Gradient = -0.000534 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3323: Gradient = -0.000544 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3333: Gradient = -0.000548 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3343: Gradient = -0.000548 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3353: Gradient = -0.000535 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3363: Gradient = -0.000542 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3373: Gradient = -0.000543 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3383: Gradient = -0.000545 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3393: Gradient = -0.000542 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3403: Gradient = -0.000541 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3413: Gradient = -0.000536 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3423: Gradient = -0.000531 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3433: Gradient = -0.000520 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3443: Gradient = -0.000530 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3453: Gradient = -0.000529 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3463: Gradient = -0.000531 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3473: Gradient = -0.000538 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3483: Gradient = -0.000520 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3493: Gradient = -0.000519 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3503: Gradient = -0.000516 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3513: Gradient = -0.000526 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3523: Gradient = -0.000518 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3533: Gradient = -0.000514 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3543: Gradient = -0.000537 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3553: Gradient = -0.000521 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3563: Gradient = -0.000515 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3573: Gradient = -0.000511 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3583: Gradient = -0.000544 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3593: Gradient = -0.000514 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3603: Gradient = -0.000527 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3613: Gradient = -0.000523 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3623: Gradient = -0.000526 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3633: Gradient = -0.000524 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3643: Gradient = -0.000519 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3653: Gradient = -0.000514 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3663: Gradient = -0.000500 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3673: Gradient = -0.000512 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3683: Gradient = -0.000492 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3693: Gradient = -0.000507 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3703: Gradient = -0.000492 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3713: Gradient = -0.000520 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3723: Gradient = -0.000498 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3733: Gradient = -0.000488 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3743: Gradient = -0.000481 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3753: Gradient = -0.000488 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3763: Gradient = -0.000490 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3773: Gradient = -0.000500 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3783: Gradient = -0.000477 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3793: Gradient = -0.000480 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3803: Gradient = -0.000502 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3813: Gradient = -0.000478 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3823: Gradient = -0.000463 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3833: Gradient = -0.000475 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3843: Gradient = -0.000472 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3853: Gradient = -0.000462 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3863: Gradient = -0.000476 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3873: Gradient = -0.000449 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3883: Gradient = -0.000455 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3893: Gradient = -0.000441 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3903: Gradient = -0.000466 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3913: Gradient = -0.000466 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3923: Gradient = -0.000455 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3933: Gradient = -0.000457 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3943: Gradient = -0.000451 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3953: Gradient = -0.000459 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3963: Gradient = -0.000455 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3973: Gradient = -0.000449 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3983: Gradient = -0.000444 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 3993: Gradient = -0.000447 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4003: Gradient = -0.000428 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4013: Gradient = -0.000442 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4023: Gradient = -0.000451 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4033: Gradient = -0.000421 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4043: Gradient = -0.000447 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4053: Gradient = -0.000474 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4063: Gradient = -0.000441 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4073: Gradient = -0.000438 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4083: Gradient = -0.000431 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4093: Gradient = -0.000419 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4103: Gradient = -0.000435 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4113: Gradient = -0.000417 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4123: Gradient = -0.000419 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4133: Gradient = -0.000425 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4143: Gradient = -0.000414 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4153: Gradient = -0.000430 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4163: Gradient = -0.000426 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4173: Gradient = -0.000440 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4183: Gradient = -0.000422 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4193: Gradient = -0.000426 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4203: Gradient = -0.000439 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4213: Gradient = -0.000401 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4223: Gradient = -0.000404 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4233: Gradient = -0.000420 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4243: Gradient = -0.000400 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4253: Gradient = -0.000396 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4263: Gradient = -0.000412 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4273: Gradient = -0.000402 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4283: Gradient = -0.000406 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4293: Gradient = -0.000404 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4303: Gradient = -0.000400 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4313: Gradient = -0.000415 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4323: Gradient = -0.000418 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4333: Gradient = -0.000406 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4343: Gradient = -0.000387 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4353: Gradient = -0.000389 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4363: Gradient = -0.000404 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4373: Gradient = -0.000422 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4383: Gradient = -0.000387 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4393: Gradient = -0.000390 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4403: Gradient = -0.000412 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4413: Gradient = -0.000381 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4423: Gradient = -0.000369 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4433: Gradient = -0.000398 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4443: Gradient = -0.000420 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4453: Gradient = -0.000393 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4463: Gradient = -0.000382 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4473: Gradient = -0.000397 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4483: Gradient = -0.000400 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4493: Gradient = -0.000393 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4503: Gradient = -0.000388 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4513: Gradient = -0.000377 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4523: Gradient = -0.000363 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4533: Gradient = -0.000376 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4543: Gradient = -0.000398 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4553: Gradient = -0.000386 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4563: Gradient = -0.000364 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4573: Gradient = -0.000359 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4583: Gradient = -0.000344 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4593: Gradient = -0.000329 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4603: Gradient = -0.000369 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4613: Gradient = -0.000378 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4623: Gradient = -0.000390 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4633: Gradient = -0.000376 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4643: Gradient = -0.000356 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4653: Gradient = -0.000358 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4663: Gradient = -0.000352 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4673: Gradient = -0.000341 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4683: Gradient = -0.000339 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4693: Gradient = -0.000370 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4703: Gradient = -0.000352 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4713: Gradient = -0.000340 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4723: Gradient = -0.000349 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4733: Gradient = -0.000333 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4743: Gradient = -0.000341 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4753: Gradient = -0.000336 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4763: Gradient = -0.000317 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4773: Gradient = -0.000328 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4783: Gradient = -0.000338 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4793: Gradient = -0.000344 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4803: Gradient = -0.000334 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4813: Gradient = -0.000312 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4823: Gradient = -0.000328 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4833: Gradient = -0.000325 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4843: Gradient = -0.000321 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4853: Gradient = -0.000323 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4863: Gradient = -0.000314 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4873: Gradient = -0.000326 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4883: Gradient = -0.000316 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4893: Gradient = -0.000316 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4903: Gradient = -0.000305 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4913: Gradient = -0.000293 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4923: Gradient = -0.000277 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4933: Gradient = -0.000292 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4943: Gradient = -0.000302 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4953: Gradient = -0.000295 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4963: Gradient = -0.000279 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4973: Gradient = -0.000306 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4983: Gradient = -0.000307 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 4993: Gradient = -0.000285 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5003: Gradient = -0.000262 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5013: Gradient = -0.000272 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5023: Gradient = -0.000286 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5033: Gradient = -0.000273 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5043: Gradient = -0.000292 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5053: Gradient = -0.000280 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5063: Gradient = -0.000266 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5073: Gradient = -0.000249 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5083: Gradient = -0.000253 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5093: Gradient = -0.000291 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5103: Gradient = -0.000274 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5113: Gradient = -0.000264 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5123: Gradient = -0.000273 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5133: Gradient = -0.000263 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5143: Gradient = -0.000250 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5153: Gradient = -0.000233 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5163: Gradient = -0.000243 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5173: Gradient = -0.000262 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5183: Gradient = -0.000235 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5193: Gradient = -0.000198 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5203: Gradient = -0.000238 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5213: Gradient = -0.000267 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5223: Gradient = -0.000244 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5233: Gradient = -0.000244 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5243: Gradient = -0.000230 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5253: Gradient = -0.000229 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5263: Gradient = -0.000224 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5273: Gradient = -0.000233 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5283: Gradient = -0.000243 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5293: Gradient = -0.000217 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5303: Gradient = -0.000217 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5313: Gradient = -0.000232 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5323: Gradient = -0.000220 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5333: Gradient = -0.000217 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5343: Gradient = -0.000214 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5353: Gradient = -0.000213 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5363: Gradient = -0.000207 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5373: Gradient = -0.000194 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5383: Gradient = -0.000165 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5393: Gradient = -0.000229 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5403: Gradient = -0.000211 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5413: Gradient = -0.000166 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5423: Gradient = -0.000218 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5433: Gradient = -0.000208 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5443: Gradient = -0.000173 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5453: Gradient = -0.000166 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5463: Gradient = -0.000176 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5473: Gradient = -0.000193 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5483: Gradient = -0.000194 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5493: Gradient = -0.000200 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5503: Gradient = -0.000192 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5513: Gradient = -0.000191 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5523: Gradient = -0.000149 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5533: Gradient = -0.000125 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5543: Gradient = -0.000139 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5553: Gradient = -0.000164 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5563: Gradient = -0.000207 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5573: Gradient = -0.000163 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5583: Gradient = -0.000155 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5593: Gradient = -0.000120 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5603: Gradient = -0.000168 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5613: Gradient = -0.000179 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5623: Gradient = -0.000176 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5633: Gradient = -0.000173 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5643: Gradient = -0.000141 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5653: Gradient = -0.000137 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5663: Gradient = -0.000108 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5673: Gradient = -0.000167 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5683: Gradient = -0.000129 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5693: Gradient = -0.000113 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5703: Gradient = -0.000113 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5713: Gradient = -0.000123 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5723: Gradient = -0.000146 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5733: Gradient = -0.000148 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5743: Gradient = -0.000156 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5753: Gradient = -0.000118 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5763: Gradient = -0.000113 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5773: Gradient = -0.000158 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5783: Gradient = -0.000119 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5793: Gradient = -0.000092 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5803: Gradient = -0.000113 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5813: Gradient = -0.000123 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5823: Gradient = -0.000102 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5833: Gradient = -0.000096 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5843: Gradient = -0.000031 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5853: Gradient = -0.000027 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5863: Gradient = -0.000018 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5873: Gradient = -0.000070 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5883: Gradient = -0.000095 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5893: Gradient = -0.000089 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5903: Gradient = -0.000016 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5913: Gradient = -0.000057 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5923: Gradient = -0.000059 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5933: Gradient = -0.000114 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5943: Gradient = -0.000101 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5953: Gradient = -0.000118 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5963: Gradient = -0.000116 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5973: Gradient = -0.000096 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5983: Gradient = -0.000051 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 5993: Gradient = 0.000036 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6003: Gradient = 0.000028 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6013: Gradient = -0.000002 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6023: Gradient = -0.000004 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6033: Gradient = -0.000028 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6043: Gradient = -0.000040 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6053: Gradient = -0.000049 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6063: Gradient = 0.000031 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6073: Gradient = 0.000037 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6083: Gradient = 0.000054 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6093: Gradient = 0.000019 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6103: Gradient = -0.000020 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6113: Gradient = -0.000034 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6123: Gradient = 0.000001 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6133: Gradient = 0.000013 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6143: Gradient = 0.000006 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6153: Gradient = 0.000006 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6163: Gradient = -0.000008 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6173: Gradient = -0.000087 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6183: Gradient = -0.000046 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6193: Gradient = 0.000024 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6203: Gradient = 0.000050 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6213: Gradient = 0.000036 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6223: Gradient = 0.000014 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6233: Gradient = -0.000008 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6243: Gradient = 0.000061 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6253: Gradient = 0.000137 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6263: Gradient = 0.000111 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6273: Gradient = 0.000077 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6283: Gradient = -0.000026 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6293: Gradient = -0.000085 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6303: Gradient = -0.000053 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6313: Gradient = 0.000019 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6323: Gradient = 0.000111 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6333: Gradient = 0.000149 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6343: Gradient = 0.000138 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6353: Gradient = 0.000036 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6363: Gradient = 0.000018 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6373: Gradient = 0.000042 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6383: Gradient = 0.000086 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6393: Gradient = 0.000037 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6403: Gradient = 0.000056 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6413: Gradient = 0.000049 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6423: Gradient = 0.000061 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6433: Gradient = 0.000075 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6443: Gradient = 0.000054 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6453: Gradient = 0.000061 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6463: Gradient = 0.000047 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6473: Gradient = 0.000075 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6483: Gradient = 0.000092 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6493: Gradient = 0.000075 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6503: Gradient = 0.000039 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6513: Gradient = 0.000065 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6523: Gradient = 0.000111 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6533: Gradient = 0.000162 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6543: Gradient = 0.000106 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6553: Gradient = 0.000104 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6563: Gradient = 0.000074 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6573: Gradient = 0.000070 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6583: Gradient = 0.000154 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6593: Gradient = 0.000127 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6603: Gradient = 0.000122 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6613: Gradient = 0.000104 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6623: Gradient = 0.000166 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6633: Gradient = 0.000140 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6643: Gradient = 0.000050 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6653: Gradient = 0.000140 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6663: Gradient = 0.000199 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6673: Gradient = 0.000189 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6683: Gradient = 0.000143 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6693: Gradient = 0.000065 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6703: Gradient = 0.000197 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6713: Gradient = 0.000206 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6723: Gradient = 0.000199 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6733: Gradient = 0.000047 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6743: Gradient = 0.000087 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6753: Gradient = -0.000180 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6763: Gradient = -0.000138 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6773: Gradient = -0.000058 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6783: Gradient = -0.000068 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6793: Gradient = -0.000204 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6803: Gradient = -0.000175 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6813: Gradient = -0.000194 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6823: Gradient = -0.000150 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6833: Gradient = -0.000066 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6843: Gradient = -0.000076 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6853: Gradient = -0.000120 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6863: Gradient = -0.000045 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6873: Gradient = -0.000140 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6883: Gradient = -0.000222 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6893: Gradient = -0.000127 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6903: Gradient = -0.000219 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6913: Gradient = -0.000155 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6923: Gradient = -0.000221 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6933: Gradient = -0.000157 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6943: Gradient = -0.000094 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6953: Gradient = -0.000094 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6963: Gradient = -0.000182 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6973: Gradient = -0.000153 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6983: Gradient = -0.000042 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 6993: Gradient = -0.000035 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7003: Gradient = -0.000147 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7013: Gradient = -0.000029 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7023: Gradient = -0.000101 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7033: Gradient = -0.000226 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7043: Gradient = -0.000161 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7053: Gradient = -0.000103 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7063: Gradient = -0.000047 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7073: Gradient = 0.000015 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7083: Gradient = -0.000059 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7093: Gradient = -0.000122 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7103: Gradient = -0.000170 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7113: Gradient = -0.000038 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7123: Gradient = -0.000096 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7133: Gradient = -0.000149 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7143: Gradient = -0.000127 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7153: Gradient = -0.000163 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7163: Gradient = -0.000144 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7173: Gradient = -0.000112 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7183: Gradient = 0.000014 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7193: Gradient = -0.000012 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7203: Gradient = -0.000067 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7213: Gradient = -0.000074 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7223: Gradient = -0.000130 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7233: Gradient = -0.000168 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7243: Gradient = -0.000146 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7253: Gradient = -0.000107 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7263: Gradient = -0.000077 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7273: Gradient = -0.000041 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7283: Gradient = -0.000003 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7293: Gradient = -0.000030 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7303: Gradient = -0.000054 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7313: Gradient = -0.000068 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7323: Gradient = -0.000108 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7333: Gradient = -0.000114 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7343: Gradient = -0.000092 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7353: Gradient = -0.000095 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7363: Gradient = -0.000068 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7373: Gradient = -0.000065 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7383: Gradient = -0.000096 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7393: Gradient = -0.000063 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7403: Gradient = -0.000072 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7413: Gradient = -0.000051 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7423: Gradient = -0.000009 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7433: Gradient = -0.000075 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7443: Gradient = -0.000048 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7453: Gradient = -0.000081 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7463: Gradient = -0.000095 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7473: Gradient = -0.000113 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7483: Gradient = -0.000107 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7493: Gradient = -0.000113 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7503: Gradient = -0.000123 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7513: Gradient = -0.000081 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7523: Gradient = -0.000110 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7533: Gradient = -0.000046 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7543: Gradient = -0.000074 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7553: Gradient = -0.000026 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7563: Gradient = -0.000059 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7573: Gradient = -0.000037 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7583: Gradient = -0.000016 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7593: Gradient = -0.000028 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7603: Gradient = -0.000030 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7613: Gradient = 0.000023 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7623: Gradient = 0.000062 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7633: Gradient = 0.000096 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7643: Gradient = 0.000088 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7653: Gradient = -0.000029 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7663: Gradient = 0.000097 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7673: Gradient = 0.000079 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7683: Gradient = -0.000007 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7693: Gradient = 0.000009 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7703: Gradient = -0.000013 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7713: Gradient = 0.000012 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7723: Gradient = -0.000072 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7733: Gradient = 0.000033 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7743: Gradient = -0.000023 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7753: Gradient = -0.000018 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7763: Gradient = -0.000025 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7773: Gradient = 0.000025 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7783: Gradient = 0.000012 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7793: Gradient = -0.000039 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7803: Gradient = -0.000090 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7813: Gradient = -0.000093 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7823: Gradient = 0.000013 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7833: Gradient = 0.000084 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7843: Gradient = 0.000044 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7853: Gradient = 0.000054 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7863: Gradient = -0.000033 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7873: Gradient = -0.000041 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7883: Gradient = -0.000002 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7893: Gradient = 0.000049 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7903: Gradient = -0.000046 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7913: Gradient = 0.000026 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7923: Gradient = -0.000006 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7933: Gradient = 0.000094 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7943: Gradient = 0.000113 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7953: Gradient = -0.000014 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7963: Gradient = -0.000082 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7973: Gradient = -0.000014 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7983: Gradient = 0.000059 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 7993: Gradient = -0.000054 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8003: Gradient = 0.000003 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8013: Gradient = 0.000045 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8023: Gradient = 0.000040 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8033: Gradient = 0.000015 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8043: Gradient = 0.000036 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8053: Gradient = 0.000013 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8063: Gradient = -0.000027 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8073: Gradient = 0.000002 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8083: Gradient = -0.000005 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8093: Gradient = 0.000044 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8103: Gradient = -0.000060 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8113: Gradient = 0.000079 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8123: Gradient = -0.000036 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8133: Gradient = 0.000027 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8143: Gradient = 0.000102 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8153: Gradient = -0.000037 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8163: Gradient = -0.000024 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8173: Gradient = -0.000019 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8183: Gradient = 0.000016 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8193: Gradient = -0.000038 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8203: Gradient = -0.000053 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8213: Gradient = 0.000014 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8223: Gradient = 0.000041 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8233: Gradient = -0.000054 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8243: Gradient = 0.000099 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8253: Gradient = 0.000036 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8263: Gradient = -0.000087 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8273: Gradient = 0.000003 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8283: Gradient = 0.000102 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8293: Gradient = 0.000072 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8303: Gradient = 0.000110 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8313: Gradient = 0.000126 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8323: Gradient = 0.000067 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8333: Gradient = 0.000008 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8343: Gradient = -0.000033 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8353: Gradient = -0.000001 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8363: Gradient = -0.000036 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8373: Gradient = 0.000039 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8383: Gradient = 0.000046 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8393: Gradient = 0.000016 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8403: Gradient = -0.000023 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8413: Gradient = -0.000023 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8423: Gradient = 0.000083 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8433: Gradient = 0.000061 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8443: Gradient = 0.000011 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8453: Gradient = 0.000006 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8463: Gradient = -0.000017 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8473: Gradient = -0.000016 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8483: Gradient = 0.000025 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8493: Gradient = -0.000006 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8503: Gradient = 0.000061 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8513: Gradient = 0.000029 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8523: Gradient = -0.000017 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8533: Gradient = 0.000069 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8543: Gradient = -0.000034 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8553: Gradient = -0.000027 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8563: Gradient = 0.000072 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8573: Gradient = 0.000019 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8583: Gradient = -0.000006 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8593: Gradient = -0.000009 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8603: Gradient = -0.000062 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8613: Gradient = 0.000054 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8623: Gradient = 0.000026 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8633: Gradient = -0.000039 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8643: Gradient = 0.000031 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8653: Gradient = 0.000030 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8663: Gradient = -0.000016 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8673: Gradient = -0.000011 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8683: Gradient = 0.000077 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8693: Gradient = -0.000003 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8703: Gradient = 0.000026 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8713: Gradient = -0.000019 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8723: Gradient = -0.000036 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8733: Gradient = -0.000060 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8743: Gradient = 0.000092 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8753: Gradient = -0.000014 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8763: Gradient = -0.000045 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8773: Gradient = 0.000066 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8783: Gradient = -0.000077 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8793: Gradient = -0.000009 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8803: Gradient = 0.000054 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8813: Gradient = 0.000151 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8823: Gradient = -0.000005 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8833: Gradient = 0.000071 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8843: Gradient = -0.000044 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8853: Gradient = -0.000053 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8863: Gradient = -0.000020 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8873: Gradient = 0.000005 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8883: Gradient = -0.000065 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8893: Gradient = 0.000031 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8903: Gradient = -0.000029 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8913: Gradient = -0.000073 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8923: Gradient = -0.000100 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8933: Gradient = -0.000028 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8943: Gradient = 0.000042 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8953: Gradient = 0.000026 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8963: Gradient = 0.000018 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8973: Gradient = 0.000000 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8983: Gradient = -0.000012 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 8993: Gradient = -0.000016 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9003: Gradient = 0.000078 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9013: Gradient = -0.000127 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9023: Gradient = -0.000063 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9033: Gradient = 0.000065 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9043: Gradient = 0.000071 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9053: Gradient = -0.000024 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9063: Gradient = -0.000082 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9073: Gradient = 0.000120 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9083: Gradient = 0.000093 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9093: Gradient = -0.000037 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9103: Gradient = 0.000030 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9113: Gradient = 0.000024 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9123: Gradient = -0.000022 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9133: Gradient = 0.000004 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9143: Gradient = 0.000055 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9153: Gradient = 0.000009 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9163: Gradient = 0.000073 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9173: Gradient = 0.000075 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9183: Gradient = -0.000029 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9193: Gradient = -0.000000 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9203: Gradient = -0.000067 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9213: Gradient = -0.000075 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9223: Gradient = 0.000003 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9233: Gradient = 0.000040 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9243: Gradient = -0.000067 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9253: Gradient = -0.000044 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9263: Gradient = 0.000102 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9273: Gradient = 0.000127 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9283: Gradient = -0.000078 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9293: Gradient = -0.000053 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9303: Gradient = -0.000027 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9313: Gradient = 0.000083 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9323: Gradient = -0.000035 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9333: Gradient = -0.000031 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9343: Gradient = 0.000033 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9353: Gradient = -0.000074 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9363: Gradient = -0.000040 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9373: Gradient = -0.000053 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9383: Gradient = -0.000025 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9393: Gradient = -0.000043 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9403: Gradient = 0.000092 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9413: Gradient = 0.000045 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9423: Gradient = -0.000096 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9433: Gradient = -0.000066 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9443: Gradient = -0.000169 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9453: Gradient = -0.000159 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9463: Gradient = -0.000067 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9473: Gradient = 0.000028 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9483: Gradient = -0.000077 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9493: Gradient = -0.000004 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9503: Gradient = 0.000023 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9513: Gradient = -0.000087 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9523: Gradient = -0.000050 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9533: Gradient = -0.000094 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9543: Gradient = -0.000012 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9553: Gradient = 0.000043 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9563: Gradient = -0.000039 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9573: Gradient = 0.000044 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9583: Gradient = 0.000021 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9593: Gradient = -0.000075 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9603: Gradient = 0.000012 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9613: Gradient = 0.000003 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9623: Gradient = 0.000008 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9633: Gradient = -0.000047 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9643: Gradient = 0.000147 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9653: Gradient = 0.000030 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9663: Gradient = 0.000010 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9673: Gradient = -0.000029 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9683: Gradient = 0.000077 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9693: Gradient = 0.000074 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9703: Gradient = -0.000011 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9713: Gradient = -0.000048 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9723: Gradient = -0.000043 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9733: Gradient = 0.000077 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9743: Gradient = 0.000166 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9753: Gradient = 0.000141 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9763: Gradient = -0.000019 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9773: Gradient = -0.000017 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9783: Gradient = 0.000068 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9793: Gradient = 0.000010 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9803: Gradient = -0.000183 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9813: Gradient = -0.000216 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9823: Gradient = -0.000064 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9833: Gradient = 0.000064 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9843: Gradient = -0.000105 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9853: Gradient = -0.000055 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9863: Gradient = 0.000044 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9873: Gradient = -0.000047 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9883: Gradient = -0.000011 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9893: Gradient = 0.000009 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9903: Gradient = 0.000018 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9913: Gradient = 0.000032 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9923: Gradient = -0.000085 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9933: Gradient = -0.000081 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9943: Gradient = -0.000011 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9953: Gradient = 0.000027 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9963: Gradient = 0.000067 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9973: Gradient = -0.000089 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9983: Gradient = -0.000046 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 9993: Gradient = -0.000038 < 0.05\n",
      "  → Increased batch size: 95 → 190\n",
      "  → Decreased learning rate: 0.001000 → 0.000500\n",
      "Epoch 10000:\n",
      "Train → MSE = 0.1257, RMSE = 0.3545, MAE = 0.2169, R² = 1.0000\n",
      "Val   → MSE = 0.3817, RMSE = 0.6178, MAE = 0.3176, R² = 1.0000\n",
      "\n",
      "Final Test Evaluation:\n",
      "MSE = 9.4919, RMSE = 3.0809, MAE = 1.1099, R² Score = 0.9995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/30 18:08:04 WARNING mlflow.utils.requirements_utils: Found torch version (2.7.1+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.7.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/07/30 18:08:12 WARNING mlflow.utils.requirements_utils: Found torch version (2.7.1+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.7.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c8a68b9bfe4f08be1cbcca32564b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'FNN_Batch_Training' already exists. Creating a new version of this model...\n",
      "2025/07/30 18:08:14 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: FNN_Batch_Training, version 10\n",
      "Created version '10' of model 'FNN_Batch_Training'.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Adaptive Batching Summary:\n",
      "  Initial batch size: 16\n",
      "  Final batch size: 190\n",
      "  Initial learning rate: 0.005000\n",
      "  Final learning rate: 0.000500\n",
      "  Number of batch size increases: 4\n",
      "\n",
      "⏳ Training completed in 118.56 seconds.\n",
      "🏃 View run Best_lr0.005_bs16_w32x16x8x4 at: http://localhost:5000/#/experiments/408745732833894938/runs/f9c0b58547644ceeb85676f5ba632b52\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/408745732833894938\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "os.chdir('./experiments/neural_networks') if not load_dotenv() else None\n",
    "load_dotenv()\n",
    "print(f\"load_dotenv() returned: {load_dotenv()}\")\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(os.getenv(\"MLFLOW_EXPERIMENT_NAME\"))\n",
    "\n",
    "# --- lr and batch_size initial values ---\n",
    "lr = 0.005  # This will be the initial learning rate, will adapt during training\n",
    "lr_min = 0.0005\n",
    "batch_size = 16  # Initial batch size instead of fixed batch size\n",
    "grad_threshold=1\n",
    "batch_multiplier=2\n",
    "lr_multiplier=0.5\n",
    "width_1st_layer = 32        \n",
    "width_2nd_layer = 16\n",
    "width_3rd_layer = 8\n",
    "width_4th_layer = 4     \n",
    "width_output_layer = 1      \n",
    "\n",
    "# --- Updated params to reflect adaptive nature ---\n",
    "params = {\n",
    "    \"dataset\": data_file_name,\n",
    "    \"width_1st_layer\": width_1st_layer,\n",
    "    \"width_2nd_layer\": width_2nd_layer,\n",
    "    \"width_3rd_layer\": width_3rd_layer,\n",
    "    \"width_4th_layer\": width_4th_layer,\n",
    "    \"width_output_layer\": width_output_layer,\n",
    "    \"activation\": \"relu\",\n",
    "    \"criterion\": \"Mean Squared Error (MSE) loss\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"adaptive_batching_learning_rate\": True,  # Flag to indicate adaptive batching\n",
    "    \"initial_lr\": lr,  # Renamed to initial_lr\n",
    "    \"initial_batch_size\": batch_size,  # Renamed to initial_batch_size\n",
    "    \"max_batch_size\": len(X_train),  # Max batch size\n",
    "    \"grad_threshold\": grad_threshold,\n",
    "    \"batch_multiplier\": batch_multiplier,\n",
    "    \"lr_multiplier\": lr_multiplier,\n",
    "    \"lr_min\": lr_min\n",
    "}\n",
    "\n",
    "# Log to MLflow\n",
    "run_name = f\"Best_lr{lr}_bs{batch_size}_w{width_1st_layer}x{width_2nd_layer}x{width_3rd_layer}x{width_4th_layer}\"\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Make it reproducible\n",
    "    SEED = 42\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Define the Neural Network Model\n",
    "    class FeedforwardNN(nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "            super(FeedforwardNN, self).__init__()\n",
    "            self.layers = nn.Sequential(\n",
    "                nn.Linear(input_size, width_1st_layer),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(width_1st_layer, width_2nd_layer),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(width_2nd_layer, width_3rd_layer),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(width_3rd_layer, width_4th_layer),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(width_4th_layer, width_output_layer),\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.layers(x)\n",
    "\n",
    "    model = FeedforwardNN(input_size=X_train.shape[1])\n",
    "    def init_weights(m):\n",
    "        '''Make the weight initialization reproducible'''\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.constant_(m.bias, 0.01)\n",
    "    model.apply(init_weights)      \n",
    "\n",
    "    # Make GPU work\n",
    "    device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "    \n",
    "    # Move data to device\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    X_val = X_val.to(device)\n",
    "    y_val = y_val.to(device)\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    \n",
    "    # --- Initialize adaptive batch trainer ---\n",
    "    adaptive_trainer = GradientAdaptiveBatchingLearning(\n",
    "        initial_batch_size=batch_size,\n",
    "        initial_lr=lr,\n",
    "        grad_threshold=grad_threshold,  # Tune this based on your loss scale\n",
    "        batch_multiplier=batch_multiplier,  # Conservative increase\n",
    "        lr_multiplier = lr_multiplier,\n",
    "        lr_min = lr_min,\n",
    "        max_batch_size=len(X_train)  # Use actual training set size\n",
    "    )\n",
    "    \n",
    "    # Create initial DataLoaders\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Training with MSE & Logging RMSE, MAE\n",
    "    def compute_rmse(predictions, targets):\n",
    "        return torch.sqrt(F.mse_loss(predictions, targets))\n",
    "    def compute_mae(predictions, targets):\n",
    "        return torch.mean(torch.abs(predictions - targets))\n",
    "    def compute_mape(predictions, targets):\n",
    "        return torch.mean(torch.abs((predictions - targets) / targets) * 100)\n",
    "    def compute_r2(predictions, targets):\n",
    "        ss_res = torch.sum((targets - predictions) ** 2)\n",
    "        ss_tot = torch.sum((targets - torch.mean(targets)) ** 2)\n",
    "        return 1 - ss_res / ss_tot\n",
    "\n",
    "    # --- Training loop with adaptive batching ---\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), adaptive_trainer.current_lr)  # Use adaptive LR\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10_000\n",
    "    trigger_times = 0\n",
    "    min_delta = 0# -0.01\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    # Track batch size and learning rate history\n",
    "    batch_size_history = []\n",
    "    lr_history = []\n",
    "\n",
    "    progress = tqdm(range(10_001), desc=\"Training\")\n",
    "    for epoch in progress:\n",
    "        # Training phase with batches\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        num_train_batches = 0\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_X)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_train_loss += loss.item()\n",
    "            num_train_batches += 1\n",
    "        \n",
    "        avg_train_loss = epoch_train_loss / num_train_batches\n",
    "\n",
    "        # Validation phase with batches\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0.0\n",
    "        num_val_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                val_output = model(batch_X)\n",
    "                val_loss = criterion(val_output, batch_y)\n",
    "                epoch_val_loss += val_loss.item()\n",
    "                num_val_batches += 1\n",
    "        \n",
    "        avg_val_loss = epoch_val_loss / num_val_batches\n",
    "        \n",
    "        # --- Adaptive batch size and learning rate update ---\n",
    "        new_batch_size, new_lr = adaptive_trainer.update_params(avg_val_loss, epoch)\n",
    "        \n",
    "        # Update optimizer learning rate if changed\n",
    "        if new_lr != optimizer.param_groups[0]['lr']:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = new_lr\n",
    "        \n",
    "        # Create new dataloader if batch size changed\n",
    "        if new_batch_size != train_loader.batch_size:\n",
    "            train_loader = DataLoader(train_dataset, batch_size=new_batch_size, shuffle=True)\n",
    "            # Also update validation loader for consistency\n",
    "            val_loader = DataLoader(val_dataset, batch_size=new_batch_size, shuffle=False)\n",
    "        \n",
    "        # Track history\n",
    "        batch_size_history.append(new_batch_size)\n",
    "        lr_history.append(new_lr)\n",
    "        \n",
    "        # For progress display \n",
    "        with torch.no_grad():\n",
    "            sample_output = model(X_train[:new_batch_size])  # Use current batch size\n",
    "            sample_rmse = compute_rmse(sample_output, y_train[:new_batch_size])\n",
    "            # Show current batch size in progress\n",
    "            progress.set_postfix({\n",
    "                \"Loss\": avg_train_loss, \n",
    "                \"RMSE\": sample_rmse.item(),\n",
    "                \"BatchSize\": new_batch_size,  # Show current batch size\n",
    "                \"LR\": f\"{new_lr:.6f}\"  # Show current learning rate\n",
    "            })\n",
    "        \n",
    "        # Save losses each epoch\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Early stopping logic\n",
    "        if avg_val_loss + min_delta < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(f\"\\n⏹️ Early stopping at epoch {epoch} — no validation improvement after {patience} epochs.\")\n",
    "                \n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    train_output = model(X_train)\n",
    "                    val_output = model(X_val)\n",
    "                    train_loss_final = criterion(train_output, y_train)\n",
    "                    val_loss_final = criterion(val_output, y_val)\n",
    "                    \n",
    "                    rmse = compute_rmse(train_output, y_train)\n",
    "                    mae = compute_mae(train_output, y_train)\n",
    "                    r2 = compute_r2(train_output, y_train)\n",
    "                    val_rmse = compute_rmse(val_output, y_val)\n",
    "                    val_mae = compute_mae(val_output, y_val)\n",
    "                    val_r2 = compute_r2(val_output, y_val)\n",
    "                    \n",
    "                print(f\"Train → MSE = {train_loss_final.item():.4f}, RMSE = {rmse.item():.4f}, MAE = {mae.item():.4f}, R² = {r2.item():.4f}\")\n",
    "                print(f\"Val   → MSE = {val_loss_final.item():.4f}, RMSE = {val_rmse.item():.4f}, MAE = {val_mae.item():.4f}, R² = {val_r2.item():.4f}\")\n",
    "                break\n",
    "\n",
    "        if epoch % 10_000 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                train_output = model(X_train)\n",
    "                val_output = model(X_val)\n",
    "                train_loss_full = criterion(train_output, y_train)\n",
    "                val_loss_full = criterion(val_output, y_val)\n",
    "                \n",
    "                rmse = compute_rmse(train_output, y_train)\n",
    "                mae = compute_mae(train_output, y_train)\n",
    "                r2 = compute_r2(train_output, y_train)\n",
    "                val_rmse = compute_rmse(val_output, y_val)\n",
    "                val_mae = compute_mae(val_output, y_val)\n",
    "                val_r2 = compute_r2(val_output, y_val)\n",
    "                \n",
    "            print(f\"Epoch {epoch}:\")\n",
    "            print(f\"Train → MSE = {train_loss_full.item():.4f}, RMSE = {rmse.item():.4f}, MAE = {mae.item():.4f}, R² = {r2.item():.4f}\")\n",
    "            print(f\"Val   → MSE = {val_loss_full.item():.4f}, RMSE = {val_rmse.item():.4f}, MAE = {val_mae.item():.4f}, R² = {val_r2.item():.4f}\")\n",
    "\n",
    "    # Metrics after all the epochs - training\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get final predictions on full datasets\n",
    "        train_output = model(X_train)\n",
    "        val_output = model(X_val)\n",
    "        test_output = model(X_test)\n",
    "        \n",
    "        # Training metrics\n",
    "        training_mse = criterion(train_output, y_train)\n",
    "        training_rmse = compute_rmse(train_output, y_train)\n",
    "        training_mae = compute_mae(train_output, y_train)\n",
    "        training_mape = compute_mape(train_output, y_train)\n",
    "        training_r2_score = compute_r2(train_output, y_train)\n",
    "    \n",
    "        # Validation metrics\n",
    "        val_mse = criterion(val_output, y_val)\n",
    "        val_rmse = compute_rmse(val_output, y_val)\n",
    "        val_mae = compute_mae(val_output, y_val)\n",
    "        val_mape = compute_mape(val_output, y_val)\n",
    "        val_r2_score = compute_r2(val_output, y_val)\n",
    "\n",
    "        # Test metrics\n",
    "        test_loss = criterion(test_output, y_test)\n",
    "        test_rmse = compute_rmse(test_output, y_test)\n",
    "        test_mae = compute_mae(test_output, y_test)\n",
    "        test_mape = compute_mape(test_output, y_test)\n",
    "        test_r2 = compute_r2(test_output, y_test)\n",
    "        \n",
    "        print(f\"\\nFinal Test Evaluation:\")\n",
    "        print(f\"MSE = {test_loss.item():.4f}, RMSE = {test_rmse.item():.4f}, MAE = {test_mae.item():.4f}, R² Score = {test_r2.item():.4f}\")\n",
    "\n",
    "    # Log metrics to MLflow\n",
    "    # training\n",
    "    mlflow.log_metric(\"training_mean_squared_error\", round(training_mse.item(), 2))\n",
    "    mlflow.log_metric(\"training_root_mean_squared_error\", round(training_rmse.item(),2))\n",
    "    mlflow.log_metric(\"training_mean_absolute_error\", round(training_mae.item(),2))\n",
    "    mlflow.log_metric(\"training_mean_absolute_percentage_error\", round(training_mape.item(),2))\n",
    "    mlflow.log_metric(\"training_r2_score\", round(training_r2_score.item(),2))\n",
    "    # val\n",
    "    mlflow.log_metric(\"val_mean_squared_error\", round(val_mse.item(), 2))\n",
    "    mlflow.log_metric(\"val_rmse\", round(val_rmse.item(),2))\n",
    "    mlflow.log_metric(\"val_mae\", round(val_mae.item(),2))\n",
    "    mlflow.log_metric(\"val_mape\", round(val_mape.item(),2))\n",
    "    mlflow.log_metric(\"val_r2_score\", round(val_r2_score.item(),2))\n",
    "    #test\n",
    "    mlflow.log_metric(\"test_mse\", round(test_loss.item(),2))\n",
    "    mlflow.log_metric(\"test_rmse\", round(test_rmse.item(),2))\n",
    "    mlflow.log_metric(\"test_mae\", round(test_mae.item(),2))\n",
    "    mlflow.log_metric(\"test_mape\", round(test_mape.item(),2))\n",
    "    mlflow.log_metric(\"test_r2_score\", round(test_r2.item(),2))\n",
    "\n",
    "    # Log the model\n",
    "    X_train_numpy = X_train.detach().cpu().numpy()\n",
    "    train_output_numpy = train_output.detach().cpu().numpy()\n",
    "    signature = infer_signature(X_train_numpy, train_output_numpy)\n",
    "    \n",
    "    mlflow.pytorch.log_model(\n",
    "        model,\n",
    "        name=\"feed_forward_neural_network\",\n",
    "        signature=signature,\n",
    "        input_example=X_train_numpy[:5],\n",
    "        registered_model_name=\"FNN_Batch_Training\"\n",
    "    )\n",
    "\n",
    "    # Model summary/architecture\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(model))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    # --- Enhanced plotting with adaptive batching info ---\n",
    "    start = 100 \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss curves (existing plot)\n",
    "    ax1.plot(range(start, len(train_losses)), train_losses[start:], label='Training Loss', color='blue')\n",
    "    ax1.plot(range(start, len(val_losses)), val_losses[start:], label='Validation Loss', color='orange')\n",
    "    #ax1.plot(range(start, len(avg_losses)), avg_losses[start:], label='Avg Loss', color='purple')\n",
    "    #ax1.axvline(x=epoch_min_avg, color='red', linestyle='--', label='Min Avg Loss')\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.set_title(\"Loss Curves\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    plt.savefig(\"loss_curves.png\")\n",
    "    mlflow.log_artifact(\"loss_curves.png\")\n",
    "    \n",
    "    # Batch size evolution\n",
    "    ax2.plot(batch_size_history, color='green')\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Batch Size\")\n",
    "    ax2.set_title(\"Batch Size Evolution\")\n",
    "    ax2.grid(True)\n",
    "    plt.savefig(\"batch_size_evolution.png\")\n",
    "    mlflow.log_artifact(\"batch_size_evolution.png\")\n",
    "    \n",
    "    # Learning rate evolution\n",
    "    ax3.plot(lr_history, color='red')\n",
    "    ax3.set_xlabel(\"Epoch\")\n",
    "    ax3.set_ylabel(\"Learning Rate\")\n",
    "    ax3.set_title(\"Learning Rate Evolution\")\n",
    "    ax3.grid(True)\n",
    "    plt.savefig(\"learning_rate_evolution.png\")\n",
    "    mlflow.log_artifact(\"learning_rate_evolution.png\")\n",
    "    \n",
    "    # Validation loss gradient (to visualize why batch size changed)\n",
    "    if len(val_losses) > 50:\n",
    "        val_gradients = np.diff(val_losses)\n",
    "        ax4.plot(val_gradients[-min(10000, len(val_gradients)):], color='orange', alpha=0.7)\n",
    "        ax4.axhline(y=adaptive_trainer.grad_threshold, color='red', linestyle='--', \n",
    "                   label=f'Threshold: {adaptive_trainer.grad_threshold}')\n",
    "        ax4.axhline(y=-adaptive_trainer.grad_threshold, color='red', linestyle='--')\n",
    "        ax4.set_xlabel(\"Epoch\")\n",
    "        ax4.set_ylabel(\"Validation Loss Gradient\")\n",
    "        ax4.set_title(\"Recent Validation Loss Gradient\")\n",
    "        ax4.legend()\n",
    "        ax4.grid(True)\n",
    "        plt.savefig(\"validation_loss_gradient.png\")\n",
    "        mlflow.log_artifact(\"validation_loss_gradient.png\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- Log adaptive batching metrics ---\n",
    "    mlflow.log_metric(\"final_batch_size\", batch_size_history[-1])\n",
    "    mlflow.log_metric(\"final_learning_rate\", lr_history[-1])\n",
    "    mlflow.log_metric(\"batch_size_increases\", len(set(batch_size_history)) - 1)\n",
    "    \n",
    "    # Print summary of adaptive batching\n",
    "    print(f\"\\n📊 Adaptive Batching Summary:\")\n",
    "    print(f\"  Initial batch size: {batch_size}\")\n",
    "    print(f\"  Final batch size: {batch_size_history[-1]}\")\n",
    "    print(f\"  Initial learning rate: {lr:.6f}\")\n",
    "    print(f\"  Final learning rate: {lr_history[-1]:.6f}\")\n",
    "    print(f\"  Number of batch size increases: {len(set(batch_size_history)) - 1}\")\n",
    "\n",
    "    # # Clean memory in case we want to run this cell again without running the whole notebook\n",
    "    # # remove references to GPU objects \n",
    "    # del model\n",
    "    # # Invoke garbage collector\n",
    "    # gc.collect()\n",
    "    # # Clear GPU cache\n",
    "    # torch.cuda.empty_cache()\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"\\n⏳ Training completed in {elapsed_time:.2f} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gtx1060_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
